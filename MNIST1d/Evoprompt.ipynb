{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5-TxL4oNCgC",
        "outputId": "cbce80cd-1b60-459f-acbd-b4903c456f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jJcUPqAf_Xl",
        "outputId": "fc1e4610-78a3-4e99-b968-c2186894af9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "\n",
        "import concurrent.futures\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import openai\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#Enter your API key\n",
        "openai.api_key = \"\"\n",
        "# pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSe5YuwLN6hJ",
        "outputId": "d645153b-b8a5-42a8-8486-13c4497d379f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 40.50%\n",
            "Epoch 1, Accuracy: 45.25%\n",
            "Epoch 1, Accuracy: 37.62%\n",
            "Epoch 2, Accuracy: 53.88%\n",
            "Epoch 2, Accuracy: 47.25%\n",
            "Epoch 2, Accuracy: 59.12%\n",
            "Epoch 3, Accuracy: 71.75%\n",
            "Epoch 3, Accuracy: 70.12%\n",
            "Epoch 3, Accuracy: 67.38%\n",
            "Epoch 4, Accuracy: 77.62%\n",
            "Epoch 4, Accuracy: 77.50%\n",
            "Epoch 4, Accuracy: 78.12%\n",
            "Epoch 5, Accuracy: 80.25%\n",
            "Epoch 5, Accuracy: 79.25%\n",
            "Epoch 5, Accuracy: 77.88%\n",
            "Epoch 6, Accuracy: 81.75%\n",
            "Epoch 6, Accuracy: 85.00%\n",
            "Epoch 6, Accuracy: 84.00%\n",
            "Epoch 7, Accuracy: 86.75%\n",
            "Epoch 7, Accuracy: 86.62%\n",
            "Epoch 7, Accuracy: 86.12%\n",
            "Epoch 8, Accuracy: 85.75%\n",
            "Epoch 8, Accuracy: 80.00%\n",
            "Epoch 8, Accuracy: 85.88%\n",
            "Epoch 9, Accuracy: 86.00%\n",
            "Epoch 9, Accuracy: 86.50%\n",
            "Epoch 9, Accuracy: 87.62%\n",
            "Epoch 10, Accuracy: 85.25%\n",
            "Final Accuracy: 85.25%, Model Size: 173002\n",
            "Epoch 10, Accuracy: 88.00%\n",
            "Final Accuracy: 88.00%, Model Size: 173002\n",
            "Epoch 10, Accuracy: 85.25%\n",
            "Final Accuracy: 85.25%, Model Size: 173002\n",
            "Epoch 1, Accuracy: 45.25%\n",
            "Epoch 1, Accuracy: 50.12%\n",
            "Epoch 1, Accuracy: 48.88%\n",
            "Epoch 2, Accuracy: 56.38%\n",
            "Epoch 2, Accuracy: 54.12%\n",
            "Epoch 2, Accuracy: 56.88%\n",
            "Epoch 3, Accuracy: 70.88%\n",
            "Epoch 3, Accuracy: 66.25%\n",
            "Epoch 3, Accuracy: 73.62%\n",
            "Epoch 4, Accuracy: 76.75%\n",
            "Epoch 4, Accuracy: 72.00%\n",
            "Epoch 4, Accuracy: 79.00%\n",
            "Epoch 5, Accuracy: 81.00%\n",
            "Epoch 5, Accuracy: 83.00%\n",
            "Epoch 5, Accuracy: 86.88%\n",
            "Epoch 6, Accuracy: 83.88%\n",
            "Epoch 6, Accuracy: 83.25%\n",
            "Epoch 6, Accuracy: 85.88%\n",
            "Epoch 7, Accuracy: 80.38%\n",
            "Epoch 7, Accuracy: 86.62%\n",
            "Epoch 7, Accuracy: 86.50%\n",
            "Epoch 8, Accuracy: 83.62%\n",
            "Epoch 8, Accuracy: 86.88%\n",
            "Epoch 8, Accuracy: 83.62%\n",
            "Epoch 9, Accuracy: 81.75%\n",
            "Epoch 9, Accuracy: 87.62%\n",
            "Epoch 9, Accuracy: 88.62%\n",
            "Epoch 10, Accuracy: 82.88%\n",
            "Finished executing code segment: accuracy=82.875, model_size=173002\n",
            "Epoch 10, Accuracy: 88.25%\n",
            "Finished executing code segment: accuracy=88.25, model_size=173002\n",
            "Epoch 10, Accuracy: 88.88%\n",
            "Finished executing code segment: accuracy=88.875, model_size=173002\n",
            "Average accuracy: 86.66666666666667, Model size: 173002\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 33.25%\n",
            "Epoch 1, Accuracy: 35.38%\n",
            "Epoch 1, Accuracy: 34.62%\n",
            "Epoch 2, Accuracy: 44.50%\n",
            "Epoch 2, Accuracy: 45.50%\n",
            "Epoch 2, Accuracy: 44.62%\n",
            "Epoch 3, Accuracy: 49.75%\n",
            "Epoch 3, Accuracy: 50.12%\n",
            "Epoch 3, Accuracy: 50.00%\n",
            "Epoch 4, Accuracy: 52.75%\n",
            "Epoch 4, Accuracy: 50.50%\n",
            "Epoch 4, Accuracy: 55.62%\n",
            "Epoch 5, Accuracy: 57.00%\n",
            "Epoch 5, Accuracy: 52.25%\n",
            "Epoch 5, Accuracy: 56.62%\n",
            "Epoch 6, Accuracy: 58.88%\n",
            "Epoch 6, Accuracy: 57.00%\n",
            "Epoch 6, Accuracy: 57.75%\n",
            "Epoch 7, Accuracy: 57.75%\n",
            "Epoch 7, Accuracy: 55.12%\n",
            "Epoch 7, Accuracy: 59.25%\n",
            "Epoch 8, Accuracy: 57.50%\n",
            "Epoch 8, Accuracy: 57.88%\n",
            "Epoch 8, Accuracy: 59.25%\n",
            "Epoch 9, Accuracy: 57.12%\n",
            "Epoch 9, Accuracy: 60.00%\n",
            "Epoch 9, Accuracy: 60.50%\n",
            "Epoch 10, Accuracy: 60.00%\n",
            "Final Accuracy: 60.00%, Model Size: 15210\n",
            "Epoch 10, Accuracy: 57.75%\n",
            "Final Accuracy: 57.75%, Model Size: 15210\n",
            "Epoch 10, Accuracy: 59.38%\n",
            "Final Accuracy: 59.38%, Model Size: 15210\n",
            "Epoch 1, Accuracy: 32.38%\n",
            "Epoch 1, Accuracy: 32.75%\n",
            "Epoch 1, Accuracy: 34.38%\n",
            "Epoch 2, Accuracy: 40.62%\n",
            "Epoch 2, Accuracy: 40.75%\n",
            "Epoch 2, Accuracy: 43.00%\n",
            "Epoch 3, Accuracy: 46.25%\n",
            "Epoch 3, Accuracy: 43.75%\n",
            "Epoch 3, Accuracy: 52.25%\n",
            "Epoch 4, Accuracy: 55.00%\n",
            "Epoch 4, Accuracy: 49.75%\n",
            "Epoch 4, Accuracy: 55.00%\n",
            "Epoch 5, Accuracy: 50.62%\n",
            "Epoch 5, Accuracy: 57.12%\n",
            "Epoch 5, Accuracy: 54.38%\n",
            "Epoch 6, Accuracy: 51.50%\n",
            "Epoch 6, Accuracy: 54.75%\n",
            "Epoch 6, Accuracy: 58.12%\n",
            "Epoch 7, Accuracy: 57.88%\n",
            "Epoch 7, Accuracy: 52.50%\n",
            "Epoch 7, Accuracy: 60.88%\n",
            "Epoch 8, Accuracy: 58.50%\n",
            "Epoch 8, Accuracy: 52.50%\n",
            "Epoch 8, Accuracy: 60.25%\n",
            "Epoch 9, Accuracy: 58.62%\n",
            "Epoch 9, Accuracy: 53.25%\n",
            "Epoch 9, Accuracy: 59.25%\n",
            "Epoch 10, Accuracy: 58.38%\n",
            "Finished executing code segment: accuracy=58.375, model_size=15210\n",
            "Epoch 10, Accuracy: 53.38%\n",
            "Finished executing code segment: accuracy=53.375, model_size=15210\n",
            "Epoch 10, Accuracy: 59.50%\n",
            "Finished executing code segment: accuracy=59.5, model_size=15210\n",
            "Average accuracy: 57.083333333333336, Model size: 15210\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segmentExecuting code segment\n",
            "\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 34.62%\n",
            "Epoch 1, Accuracy: 34.50%\n",
            "Epoch 1, Accuracy: 39.00%\n",
            "Epoch 2, Accuracy: 43.88%\n",
            "Epoch 2, Accuracy: 42.38%\n",
            "Epoch 2, Accuracy: 43.12%\n",
            "Epoch 3, Accuracy: 46.88%\n",
            "Epoch 3, Accuracy: 46.62%\n",
            "Epoch 3, Accuracy: 47.62%\n",
            "Epoch 4, Accuracy: 51.62%\n",
            "Epoch 4, Accuracy: 48.25%\n",
            "Epoch 4, Accuracy: 46.50%\n",
            "Epoch 5, Accuracy: 58.75%\n",
            "Epoch 5, Accuracy: 55.00%\n",
            "Epoch 5, Accuracy: 52.12%\n",
            "Epoch 6, Accuracy: 56.12%\n",
            "Epoch 6, Accuracy: 58.38%\n",
            "Epoch 6, Accuracy: 52.25%\n",
            "Epoch 7, Accuracy: 61.12%\n",
            "Epoch 7, Accuracy: 62.50%\n",
            "Epoch 7, Accuracy: 57.75%\n",
            "Epoch 8, Accuracy: 64.00%\n",
            "Epoch 8, Accuracy: 64.38%\n",
            "Epoch 8, Accuracy: 57.00%\n",
            "Epoch 9, Accuracy: 65.75%\n",
            "Epoch 9, Accuracy: 63.88%\n",
            "Epoch 9, Accuracy: 61.75%\n",
            "Epoch 10, Accuracy: 64.00%\n",
            "Final Accuracy: 64.00%, Model Size: 12710\n",
            "Epoch 10, Accuracy: 70.00%\n",
            "Final Accuracy: 70.00%, Model Size: 12710\n",
            "Epoch 10, Accuracy: 65.25%\n",
            "Final Accuracy: 65.25%, Model Size: 12710\n",
            "Epoch 1, Accuracy: 37.75%\n",
            "Epoch 1, Accuracy: 37.62%\n",
            "Epoch 1, Accuracy: 36.62%\n",
            "Epoch 2, Accuracy: 44.62%\n",
            "Epoch 2, Accuracy: 44.50%\n",
            "Epoch 2, Accuracy: 44.62%\n",
            "Epoch 3, Accuracy: 44.75%\n",
            "Epoch 3, Accuracy: 50.62%\n",
            "Epoch 3, Accuracy: 47.50%\n",
            "Epoch 4, Accuracy: 49.12%\n",
            "Epoch 4, Accuracy: 53.38%\n",
            "Epoch 4, Accuracy: 50.62%\n",
            "Epoch 5, Accuracy: 56.12%\n",
            "Epoch 5, Accuracy: 56.12%\n",
            "Epoch 5, Accuracy: 54.88%\n",
            "Epoch 6, Accuracy: 58.12%\n",
            "Epoch 6, Accuracy: 60.38%\n",
            "Epoch 6, Accuracy: 57.38%\n",
            "Epoch 7, Accuracy: 63.25%\n",
            "Epoch 7, Accuracy: 59.50%\n",
            "Epoch 7, Accuracy: 61.38%\n",
            "Epoch 8, Accuracy: 65.50%\n",
            "Epoch 8, Accuracy: 63.62%\n",
            "Epoch 8, Accuracy: 62.38%\n",
            "Epoch 9, Accuracy: 68.12%\n",
            "Epoch 9, Accuracy: 68.00%\n",
            "Epoch 9, Accuracy: 65.88%\n",
            "Epoch 10, Accuracy: 69.88%\n",
            "Finished executing code segment: accuracy=69.875, model_size=12710\n",
            "Epoch 10, Accuracy: 69.62%\n",
            "Finished executing code segment: accuracy=69.625, model_size=12710\n",
            "Epoch 10, Accuracy: 71.12%\n",
            "Finished executing code segment: accuracy=71.125, model_size=12710\n",
            "Average accuracy: 70.20833333333333, Model size: 12710\n",
            "Evaluating child : \n",
            " #Child\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 20\n",
            "    def __init__(self):\n",
            "          super(Child, self).__init__()\n",
            "          self.conv1 = nn.Conv2d(in_channels = 1, out_channels = self.features, kernel_size=(3,1), stride=(2,1), padding=(1,))\n",
            "          self.relu1 = nn.ReLU()\n",
            "\n",
            "          self.conv_layers = nn.ModuleList()\n",
            "          for _ in range(2):\n",
            "              self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels = self.features, kernel_size=(3,1), stride =(2,1), padding = (1,)))\n",
            "              self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "          self.flatten = nn.Flatten()\n",
            "          self.conv_out_size = self._get_conv_out_size()\n",
            "          self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size()\n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.relu1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "\n",
            "    child_model = Child()\n",
            "\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 37.12%\n",
            "Epoch 1, Accuracy: 35.12%\n",
            "Epoch 1, Accuracy: 35.88%\n",
            "Epoch 2, Accuracy: 41.62%\n",
            "Epoch 2, Accuracy: 41.62%\n",
            "Epoch 2, Accuracy: 43.88%\n",
            "Epoch 3, Accuracy: 45.88%\n",
            "Epoch 3, Accuracy: 45.75%\n",
            "Epoch 3, Accuracy: 48.88%\n",
            "Epoch 4, Accuracy: 50.00%\n",
            "Epoch 4, Accuracy: 49.88%\n",
            "Epoch 4, Accuracy: 48.62%\n",
            "Epoch 5, Accuracy: 47.12%\n",
            "Epoch 5, Accuracy: 52.12%\n",
            "Epoch 5, Accuracy: 52.88%\n",
            "Epoch 6, Accuracy: 53.75%\n",
            "Epoch 6, Accuracy: 57.88%\n",
            "Epoch 6, Accuracy: 54.75%\n",
            "Epoch 7, Accuracy: 49.38%\n",
            "Epoch 7, Accuracy: 59.62%\n",
            "Epoch 7, Accuracy: 55.25%\n",
            "Epoch 8, Accuracy: 52.88%\n",
            "Epoch 8, Accuracy: 62.50%\n",
            "Epoch 8, Accuracy: 60.75%\n",
            "Epoch 9, Accuracy: 55.12%\n",
            "Epoch 9, Accuracy: 63.38%\n",
            "Epoch 9, Accuracy: 62.88%\n",
            "Epoch 10, Accuracy: 52.50%\n",
            "Final Accuracy: 52.50%, Model Size: 9530\n",
            "Epoch 10, Accuracy: 65.00%\n",
            "Final Accuracy: 65.00%, Model Size: 9530\n",
            "Epoch 10, Accuracy: 63.12%\n",
            "Final Accuracy: 63.12%, Model Size: 9530\n",
            "Epoch 1, Accuracy: 38.12%\n",
            "Epoch 1, Accuracy: 35.62%\n",
            "Epoch 1, Accuracy: 36.50%\n",
            "Epoch 2, Accuracy: 44.38%\n",
            "Epoch 2, Accuracy: 43.88%\n",
            "Epoch 2, Accuracy: 38.75%\n",
            "Epoch 3, Accuracy: 49.00%\n",
            "Epoch 3, Accuracy: 48.62%\n",
            "Epoch 3, Accuracy: 46.88%\n",
            "Epoch 4, Accuracy: 47.62%\n",
            "Epoch 4, Accuracy: 47.75%\n",
            "Epoch 4, Accuracy: 48.12%\n",
            "Epoch 5, Accuracy: 52.00%\n",
            "Epoch 5, Accuracy: 49.00%\n",
            "Epoch 5, Accuracy: 51.88%\n",
            "Epoch 6, Accuracy: 53.75%\n",
            "Epoch 6, Accuracy: 54.00%\n",
            "Epoch 6, Accuracy: 49.00%\n",
            "Epoch 7, Accuracy: 55.25%\n",
            "Epoch 7, Accuracy: 57.62%\n",
            "Epoch 7, Accuracy: 58.88%\n",
            "Epoch 8, Accuracy: 58.88%\n",
            "Epoch 8, Accuracy: 56.12%\n",
            "Epoch 8, Accuracy: 59.88%\n",
            "Epoch 9, Accuracy: 58.75%\n",
            "Epoch 9, Accuracy: 60.38%\n",
            "Epoch 9, Accuracy: 61.00%\n",
            "Epoch 10, Accuracy: 60.25%\n",
            "Finished executing code segment: accuracy=60.25, model_size=9530\n",
            "Epoch 10, Accuracy: 61.12%\n",
            "Finished executing code segment: accuracy=61.125, model_size=9530\n",
            "Epoch 10, Accuracy: 57.50%\n",
            "Finished executing code segment: accuracy=57.5, model_size=9530\n",
            "Average accuracy: 59.625, Model size: 9530\n",
            "Evaluating child : \n",
            " #Child\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 16\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=128)\n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size()\n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]\n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "def main():\n",
            "\n",
            "    with open(\"mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "\n",
            "    child_model = Child()\n",
            "\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):\n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "An error occurred: Moving to the next iteration [Errno 2] No such file or directory: 'mnist1d_data.pkl'\n",
            "An error occurred: Moving to the next iteration [Errno 2] No such file or directory: 'mnist1d_data.pkl'\n",
            "Executing code segment\n",
            "An error occurred: Moving to the next iteration [Errno 2] No such file or directory: 'mnist1d_data.pkl'\n",
            "Average accuracy: 0.0, Model size: 0\n",
            "Error in child code generated by the GPT\n",
            "Evaluating child : \n",
            " #Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 16\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=128) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 41.50%\n",
            "Epoch 1, Accuracy: 43.50%\n",
            "Epoch 1, Accuracy: 44.00%\n",
            "Epoch 2, Accuracy: 49.38%\n",
            "Epoch 2, Accuracy: 56.00%\n",
            "Epoch 2, Accuracy: 61.12%\n",
            "Epoch 3, Accuracy: 55.88%\n",
            "Epoch 3, Accuracy: 63.00%\n",
            "Epoch 3, Accuracy: 66.25%\n",
            "Epoch 4, Accuracy: 68.00%\n",
            "Epoch 4, Accuracy: 68.12%\n",
            "Epoch 4, Accuracy: 71.62%\n",
            "Epoch 5, Accuracy: 69.88%\n",
            "Epoch 5, Accuracy: 68.75%\n",
            "Epoch 5, Accuracy: 73.62%\n",
            "Epoch 6, Accuracy: 72.62%\n",
            "Epoch 6, Accuracy: 76.12%\n",
            "Epoch 6, Accuracy: 74.88%\n",
            "Epoch 7, Accuracy: 74.62%\n",
            "Epoch 7, Accuracy: 75.62%\n",
            "Epoch 7, Accuracy: 76.75%\n",
            "Epoch 8, Accuracy: 74.25%\n",
            "Epoch 8, Accuracy: 76.88%\n",
            "Epoch 8, Accuracy: 78.75%\n",
            "Epoch 9, Accuracy: 79.50%\n",
            "Epoch 9, Accuracy: 80.62%\n",
            "Epoch 9, Accuracy: 77.75%\n",
            "Epoch 10, Accuracy: 79.12%\n",
            "Final Accuracy: 79.12%, Model Size: 43226\n",
            "Epoch 10, Accuracy: 79.12%\n",
            "Final Accuracy: 79.12%, Model Size: 43226\n",
            "Epoch 10, Accuracy: 80.38%\n",
            "Final Accuracy: 80.38%, Model Size: 43226\n",
            "Epoch 1, Accuracy: 41.12%\n",
            "Epoch 1, Accuracy: 40.00%\n",
            "Epoch 1, Accuracy: 40.88%\n",
            "Epoch 2, Accuracy: 48.75%\n",
            "Epoch 2, Accuracy: 48.88%\n",
            "Epoch 2, Accuracy: 53.75%\n",
            "Epoch 3, Accuracy: 58.75%\n",
            "Epoch 3, Accuracy: 58.12%\n",
            "Epoch 3, Accuracy: 64.75%\n",
            "Epoch 4, Accuracy: 67.00%\n",
            "Epoch 4, Accuracy: 63.88%\n",
            "Epoch 4, Accuracy: 70.50%\n",
            "Epoch 5, Accuracy: 72.12%\n",
            "Epoch 5, Accuracy: 64.38%\n",
            "Epoch 5, Accuracy: 71.25%\n",
            "Epoch 6, Accuracy: 74.75%\n",
            "Epoch 6, Accuracy: 73.50%\n",
            "Epoch 6, Accuracy: 76.38%\n",
            "Epoch 7, Accuracy: 75.25%\n",
            "Epoch 7, Accuracy: 76.00%\n",
            "Epoch 7, Accuracy: 80.25%\n",
            "Epoch 8, Accuracy: 76.50%\n",
            "Epoch 8, Accuracy: 76.88%\n",
            "Epoch 8, Accuracy: 79.50%\n",
            "Epoch 9, Accuracy: 76.12%\n",
            "Epoch 9, Accuracy: 76.75%\n",
            "Epoch 9, Accuracy: 80.00%\n",
            "Epoch 10, Accuracy: 76.75%\n",
            "Finished executing code segment: accuracy=76.75, model_size=43226\n",
            "Epoch 10, Accuracy: 79.88%\n",
            "Finished executing code segment: accuracy=79.875, model_size=43226\n",
            "Epoch 10, Accuracy: 81.88%\n",
            "Finished executing code segment: accuracy=81.875, model_size=43226\n",
            "Average accuracy: 79.5, Model size: 43226\n",
            "Evaluating child : \n",
            " #Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 32\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=64) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 44.62%\n",
            "Epoch 1, Accuracy: 43.12%\n",
            "Epoch 1, Accuracy: 45.12%\n",
            "Epoch 2, Accuracy: 57.88%\n",
            "Epoch 2, Accuracy: 59.38%\n",
            "Epoch 2, Accuracy: 59.50%\n",
            "Epoch 3, Accuracy: 65.62%\n",
            "Epoch 3, Accuracy: 68.50%\n",
            "Epoch 3, Accuracy: 65.25%\n",
            "Epoch 4, Accuracy: 71.50%\n",
            "Epoch 4, Accuracy: 70.00%\n",
            "Epoch 4, Accuracy: 73.25%\n",
            "Epoch 5, Accuracy: 77.12%\n",
            "Epoch 5, Accuracy: 73.00%\n",
            "Epoch 5, Accuracy: 76.75%\n",
            "Epoch 6, Accuracy: 77.75%\n",
            "Epoch 6, Accuracy: 76.50%\n",
            "Epoch 6, Accuracy: 79.12%\n",
            "Epoch 7, Accuracy: 79.25%\n",
            "Epoch 7, Accuracy: 79.38%\n",
            "Epoch 7, Accuracy: 83.12%\n",
            "Epoch 8, Accuracy: 81.50%\n",
            "Epoch 8, Accuracy: 80.00%\n",
            "Epoch 8, Accuracy: 82.88%\n",
            "Epoch 9, Accuracy: 80.38%\n",
            "Epoch 9, Accuracy: 79.38%\n",
            "Epoch 9, Accuracy: 83.12%\n",
            "Epoch 10, Accuracy: 82.00%\n",
            "Final Accuracy: 82.00%, Model Size: 44906\n",
            "Epoch 10, Accuracy: 81.62%\n",
            "Final Accuracy: 81.62%, Model Size: 44906\n",
            "Epoch 10, Accuracy: 82.38%\n",
            "Final Accuracy: 82.38%, Model Size: 44906\n",
            "Epoch 1, Accuracy: 49.38%\n",
            "Epoch 1, Accuracy: 46.75%\n",
            "Epoch 1, Accuracy: 42.62%\n",
            "Epoch 2, Accuracy: 60.38%\n",
            "Epoch 2, Accuracy: 59.38%\n",
            "Epoch 2, Accuracy: 51.50%\n",
            "Epoch 3, Accuracy: 71.38%\n",
            "Epoch 3, Accuracy: 69.75%\n",
            "Epoch 3, Accuracy: 63.00%\n",
            "Epoch 4, Accuracy: 76.12%\n",
            "Epoch 4, Accuracy: 75.25%\n",
            "Epoch 4, Accuracy: 68.75%\n",
            "Epoch 5, Accuracy: 78.88%\n",
            "Epoch 5, Accuracy: 76.38%\n",
            "Epoch 5, Accuracy: 76.25%\n",
            "Epoch 6, Accuracy: 79.50%\n",
            "Epoch 6, Accuracy: 77.25%\n",
            "Epoch 6, Accuracy: 78.50%\n",
            "Epoch 7, Accuracy: 82.00%\n",
            "Epoch 7, Accuracy: 80.62%\n",
            "Epoch 7, Accuracy: 82.50%\n",
            "Epoch 8, Accuracy: 84.12%\n",
            "Epoch 8, Accuracy: 81.00%\n",
            "Epoch 8, Accuracy: 81.88%\n",
            "Epoch 9, Accuracy: 85.88%\n",
            "Epoch 9, Accuracy: 81.12%\n",
            "Epoch 9, Accuracy: 82.88%\n",
            "Epoch 10, Accuracy: 85.00%\n",
            "Finished executing code segment: accuracy=85.0, model_size=44906\n",
            "Epoch 10, Accuracy: 82.75%\n",
            "Finished executing code segment: accuracy=82.75, model_size=44906\n",
            "Epoch 10, Accuracy: 83.00%\n",
            "Finished executing code segment: accuracy=83.0, model_size=44906\n",
            "Average accuracy: 83.58333333333333, Model size: 44906\n",
            "Evaluating child : \n",
            " # New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 20\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=128) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 41.25%\n",
            "Epoch 1, Accuracy: 45.25%Epoch 1, Accuracy: 44.38%\n",
            "\n",
            "Epoch 2, Accuracy: 49.75%\n",
            "Epoch 2, Accuracy: 57.25%\n",
            "Epoch 2, Accuracy: 50.62%\n",
            "Epoch 3, Accuracy: 53.62%\n",
            "Epoch 3, Accuracy: 52.75%\n",
            "Epoch 3, Accuracy: 62.25%\n",
            "Epoch 4, Accuracy: 71.25%Epoch 4, Accuracy: 56.75%\n",
            "\n",
            "Epoch 4, Accuracy: 58.75%\n",
            "Epoch 5, Accuracy: 72.88%\n",
            "Epoch 5, Accuracy: 65.38%\n",
            "Epoch 5, Accuracy: 60.25%\n",
            "Epoch 6, Accuracy: 75.88%\n",
            "Epoch 6, Accuracy: 69.88%\n",
            "Epoch 6, Accuracy: 63.75%\n",
            "Epoch 7, Accuracy: 78.88%\n",
            "Epoch 7, Accuracy: 71.12%\n",
            "Epoch 7, Accuracy: 68.50%\n",
            "Epoch 8, Accuracy: 76.75%\n",
            "Epoch 8, Accuracy: 73.38%\n",
            "Epoch 8, Accuracy: 70.12%\n",
            "Epoch 9, Accuracy: 77.88%\n",
            "Epoch 9, Accuracy: 71.88%\n",
            "Epoch 9, Accuracy: 68.62%\n",
            "Epoch 10, Accuracy: 80.00%\n",
            "Final Accuracy: 80.00%, Model Size: 53918\n",
            "Epoch 10, Accuracy: 75.62%\n",
            "Final Accuracy: 75.62%, Model Size: 53918\n",
            "Epoch 10, Accuracy: 70.75%\n",
            "Final Accuracy: 70.75%, Model Size: 53918\n",
            "Epoch 1, Accuracy: 43.38%\n",
            "Epoch 1, Accuracy: 39.38%\n",
            "Epoch 1, Accuracy: 40.88%\n",
            "Epoch 2, Accuracy: 45.25%\n",
            "Epoch 2, Accuracy: 48.00%\n",
            "Epoch 2, Accuracy: 49.50%\n",
            "Epoch 3, Accuracy: 52.75%\n",
            "Epoch 3, Accuracy: 52.12%\n",
            "Epoch 3, Accuracy: 55.38%\n",
            "Epoch 4, Accuracy: 59.88%\n",
            "Epoch 4, Accuracy: 56.38%\n",
            "Epoch 4, Accuracy: 63.25%\n",
            "Epoch 5, Accuracy: 60.50%\n",
            "Epoch 5, Accuracy: 59.12%\n",
            "Epoch 5, Accuracy: 66.12%\n",
            "Epoch 6, Accuracy: 66.88%\n",
            "Epoch 6, Accuracy: 66.00%\n",
            "Epoch 6, Accuracy: 70.50%\n",
            "Epoch 7, Accuracy: 69.50%\n",
            "Epoch 7, Accuracy: 71.50%\n",
            "Epoch 7, Accuracy: 72.88%\n",
            "Epoch 8, Accuracy: 69.88%\n",
            "Epoch 8, Accuracy: 70.38%\n",
            "Epoch 8, Accuracy: 74.25%\n",
            "Epoch 9, Accuracy: 74.00%\n",
            "Epoch 9, Accuracy: 73.62%\n",
            "Epoch 9, Accuracy: 74.00%\n",
            "Epoch 10, Accuracy: 74.12%\n",
            "Finished executing code segment: accuracy=74.125, model_size=53918\n",
            "Epoch 10, Accuracy: 75.38%\n",
            "Finished executing code segment: accuracy=75.375, model_size=53918\n",
            "Epoch 10, Accuracy: 75.38%\n",
            "Finished executing code segment: accuracy=75.375, model_size=53918\n",
            "Average accuracy: 74.95833333333333, Model size: 53918\n",
            "Evaluating child : \n",
            " # New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 16\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=64) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 41.25%\n",
            "Epoch 1, Accuracy: 41.25%\n",
            "Epoch 1, Accuracy: 36.62%\n",
            "Epoch 2, Accuracy: 48.00%\n",
            "Epoch 2, Accuracy: 51.62%\n",
            "Epoch 2, Accuracy: 45.25%\n",
            "Epoch 3, Accuracy: 54.25%\n",
            "Epoch 3, Accuracy: 59.50%\n",
            "Epoch 3, Accuracy: 57.25%\n",
            "Epoch 4, Accuracy: 63.38%\n",
            "Epoch 4, Accuracy: 63.25%\n",
            "Epoch 4, Accuracy: 62.38%\n",
            "Epoch 5, Accuracy: 71.75%\n",
            "Epoch 5, Accuracy: 68.88%\n",
            "Epoch 5, Accuracy: 67.75%\n",
            "Epoch 6, Accuracy: 72.75%\n",
            "Epoch 6, Accuracy: 72.50%\n",
            "Epoch 6, Accuracy: 70.25%\n",
            "Epoch 7, Accuracy: 75.75%\n",
            "Epoch 7, Accuracy: 74.88%\n",
            "Epoch 7, Accuracy: 73.62%\n",
            "Epoch 8, Accuracy: 77.75%\n",
            "Epoch 8, Accuracy: 76.88%\n",
            "Epoch 8, Accuracy: 75.75%\n",
            "Epoch 9, Accuracy: 74.75%\n",
            "Epoch 9, Accuracy: 78.25%\n",
            "Epoch 9, Accuracy: 76.50%\n",
            "Epoch 10, Accuracy: 81.38%\n",
            "Final Accuracy: 81.38%, Model Size: 22042\n",
            "Epoch 10, Accuracy: 81.00%\n",
            "Final Accuracy: 81.00%, Model Size: 22042\n",
            "Epoch 10, Accuracy: 77.62%\n",
            "Final Accuracy: 77.62%, Model Size: 22042\n",
            "Epoch 1, Accuracy: 43.75%\n",
            "Epoch 1, Accuracy: 39.62%\n",
            "Epoch 1, Accuracy: 41.38%\n",
            "Epoch 2, Accuracy: 47.88%\n",
            "Epoch 2, Accuracy: 45.62%\n",
            "Epoch 2, Accuracy: 48.25%\n",
            "Epoch 3, Accuracy: 60.62%\n",
            "Epoch 3, Accuracy: 51.38%\n",
            "Epoch 3, Accuracy: 57.38%\n",
            "Epoch 4, Accuracy: 64.25%\n",
            "Epoch 4, Accuracy: 57.50%\n",
            "Epoch 4, Accuracy: 62.50%\n",
            "Epoch 5, Accuracy: 68.88%\n",
            "Epoch 5, Accuracy: 59.62%\n",
            "Epoch 5, Accuracy: 71.00%\n",
            "Epoch 6, Accuracy: 74.38%\n",
            "Epoch 6, Accuracy: 64.62%\n",
            "Epoch 6, Accuracy: 68.75%\n",
            "Epoch 7, Accuracy: 76.12%\n",
            "Epoch 7, Accuracy: 68.25%\n",
            "Epoch 7, Accuracy: 75.12%\n",
            "Epoch 8, Accuracy: 78.75%\n",
            "Epoch 8, Accuracy: 70.00%\n",
            "Epoch 8, Accuracy: 76.75%\n",
            "Epoch 9, Accuracy: 77.38%\n",
            "Epoch 9, Accuracy: 72.75%\n",
            "Epoch 9, Accuracy: 77.00%\n",
            "Epoch 10, Accuracy: 79.00%\n",
            "Finished executing code segment: accuracy=79.0, model_size=22042\n",
            "Epoch 10, Accuracy: 76.88%\n",
            "Finished executing code segment: accuracy=76.875, model_size=22042\n",
            "Epoch 10, Accuracy: 79.38%\n",
            "Finished executing code segment: accuracy=79.375, model_size=22042\n",
            "Average accuracy: 78.41666666666667, Model size: 22042\n",
            "Evaluating child : \n",
            " # New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 16\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=64) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 41.62%\n",
            "Epoch 1, Accuracy: 42.38%\n",
            "Epoch 1, Accuracy: 37.50%\n",
            "Epoch 2, Accuracy: 55.50%\n",
            "Epoch 2, Accuracy: 46.38%\n",
            "Epoch 2, Accuracy: 50.00%\n",
            "Epoch 3, Accuracy: 65.00%\n",
            "Epoch 3, Accuracy: 49.75%\n",
            "Epoch 3, Accuracy: 55.50%\n",
            "Epoch 4, Accuracy: 64.25%\n",
            "Epoch 4, Accuracy: 51.88%\n",
            "Epoch 4, Accuracy: 60.88%\n",
            "Epoch 5, Accuracy: 72.25%\n",
            "Epoch 5, Accuracy: 54.25%\n",
            "Epoch 5, Accuracy: 65.75%\n",
            "Epoch 6, Accuracy: 75.75%\n",
            "Epoch 6, Accuracy: 60.88%\n",
            "Epoch 6, Accuracy: 70.88%\n",
            "Epoch 7, Accuracy: 78.38%\n",
            "Epoch 7, Accuracy: 61.62%\n",
            "Epoch 7, Accuracy: 71.38%\n",
            "Epoch 8, Accuracy: 80.12%\n",
            "Epoch 8, Accuracy: 65.50%\n",
            "Epoch 8, Accuracy: 75.00%\n",
            "Epoch 9, Accuracy: 80.00%\n",
            "Epoch 9, Accuracy: 68.50%\n",
            "Epoch 9, Accuracy: 74.38%\n",
            "Epoch 10, Accuracy: 79.62%\n",
            "Final Accuracy: 79.62%, Model Size: 22042\n",
            "Epoch 10, Accuracy: 71.50%\n",
            "Final Accuracy: 71.50%, Model Size: 22042\n",
            "Epoch 10, Accuracy: 78.75%\n",
            "Final Accuracy: 78.75%, Model Size: 22042\n",
            "Epoch 1, Accuracy: 41.62%\n",
            "Epoch 1, Accuracy: 44.12%\n",
            "Epoch 1, Accuracy: 39.38%\n",
            "Epoch 2, Accuracy: 45.62%\n",
            "Epoch 2, Accuracy: 56.25%\n",
            "Epoch 2, Accuracy: 42.62%\n",
            "Epoch 3, Accuracy: 52.62%\n",
            "Epoch 3, Accuracy: 64.00%\n",
            "Epoch 3, Accuracy: 52.00%\n",
            "Epoch 4, Accuracy: 59.62%\n",
            "Epoch 4, Accuracy: 71.12%\n",
            "Epoch 4, Accuracy: 58.38%\n",
            "Epoch 5, Accuracy: 66.50%\n",
            "Epoch 5, Accuracy: 74.00%\n",
            "Epoch 5, Accuracy: 67.12%\n",
            "Epoch 6, Accuracy: 69.62%\n",
            "Epoch 6, Accuracy: 73.12%\n",
            "Epoch 6, Accuracy: 72.12%\n",
            "Epoch 7, Accuracy: 73.75%\n",
            "Epoch 7, Accuracy: 77.88%\n",
            "Epoch 7, Accuracy: 72.75%\n",
            "Epoch 8, Accuracy: 74.25%\n",
            "Epoch 8, Accuracy: 78.38%\n",
            "Epoch 8, Accuracy: 72.00%\n",
            "Epoch 9, Accuracy: 75.50%\n",
            "Epoch 9, Accuracy: 78.00%\n",
            "Epoch 9, Accuracy: 73.38%\n",
            "Epoch 10, Accuracy: 77.25%\n",
            "Finished executing code segment: accuracy=77.25, model_size=22042\n",
            "Epoch 10, Accuracy: 81.12%\n",
            "Finished executing code segment: accuracy=81.125, model_size=22042\n",
            "Epoch 10, Accuracy: 75.25%\n",
            "Finished executing code segment: accuracy=75.25, model_size=22042\n",
            "Average accuracy: 77.875, Model size: 22042\n",
            "Evaluating child : \n",
            " # New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 16\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=64) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  \n",
            "        x = self.conv1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 41.12%\n",
            "Epoch 1, Accuracy: 37.62%\n",
            "Epoch 1, Accuracy: 42.00%\n",
            "Epoch 2, Accuracy: 54.50%\n",
            "Epoch 2, Accuracy: 45.62%\n",
            "Epoch 2, Accuracy: 45.50%\n",
            "Epoch 3, Accuracy: 54.62%\n",
            "Epoch 3, Accuracy: 58.50%\n",
            "Epoch 3, Accuracy: 48.00%\n",
            "Epoch 4, Accuracy: 61.38%\n",
            "Epoch 4, Accuracy: 54.38%\n",
            "Epoch 4, Accuracy: 67.50%\n",
            "Epoch 5, Accuracy: 67.25%\n",
            "Epoch 5, Accuracy: 57.50%\n",
            "Epoch 5, Accuracy: 72.12%\n",
            "Epoch 6, Accuracy: 66.50%\n",
            "Epoch 6, Accuracy: 68.12%\n",
            "Epoch 6, Accuracy: 74.88%\n",
            "Epoch 7, Accuracy: 73.00%\n",
            "Epoch 7, Accuracy: 72.38%\n",
            "Epoch 7, Accuracy: 76.88%\n",
            "Epoch 8, Accuracy: 76.75%\n",
            "Epoch 8, Accuracy: 73.00%\n",
            "Epoch 8, Accuracy: 77.50%\n",
            "Epoch 9, Accuracy: 78.50%\n",
            "Epoch 9, Accuracy: 73.50%\n",
            "Epoch 9, Accuracy: 78.25%\n",
            "Epoch 10, Accuracy: 78.12%\n",
            "Final Accuracy: 78.12%, Model Size: 22042\n",
            "Epoch 10, Accuracy: 76.25%\n",
            "Final Accuracy: 76.25%, Model Size: 22042\n",
            "Epoch 10, Accuracy: 78.50%\n",
            "Final Accuracy: 78.50%, Model Size: 22042\n",
            "Epoch 1, Accuracy: 41.25%\n",
            "Epoch 1, Accuracy: 40.88%\n",
            "Epoch 1, Accuracy: 42.12%\n",
            "Epoch 2, Accuracy: 46.38%\n",
            "Epoch 2, Accuracy: 47.00%\n",
            "Epoch 2, Accuracy: 49.00%\n",
            "Epoch 3, Accuracy: 51.12%\n",
            "Epoch 3, Accuracy: 61.50%\n",
            "Epoch 3, Accuracy: 59.00%\n",
            "Epoch 4, Accuracy: 64.12%\n",
            "Epoch 4, Accuracy: 62.00%\n",
            "Epoch 4, Accuracy: 67.75%\n",
            "Epoch 5, Accuracy: 68.62%\n",
            "Epoch 5, Accuracy: 67.25%\n",
            "Epoch 5, Accuracy: 70.75%\n",
            "Epoch 6, Accuracy: 72.38%\n",
            "Epoch 6, Accuracy: 71.75%\n",
            "Epoch 6, Accuracy: 74.38%\n",
            "Epoch 7, Accuracy: 76.00%\n",
            "Epoch 7, Accuracy: 73.12%\n",
            "Epoch 7, Accuracy: 72.38%\n",
            "Epoch 8, Accuracy: 77.75%\n",
            "Epoch 8, Accuracy: 74.12%\n",
            "Epoch 8, Accuracy: 77.25%\n",
            "Epoch 9, Accuracy: 80.00%\n",
            "Epoch 9, Accuracy: 75.62%\n",
            "Epoch 9, Accuracy: 77.00%\n",
            "Epoch 10, Accuracy: 78.12%\n",
            "Finished executing code segment: accuracy=78.125, model_size=22042\n",
            "Epoch 10, Accuracy: 76.00%\n",
            "Finished executing code segment: accuracy=76.0, model_size=22042\n",
            "Epoch 10, Accuracy: 79.12%\n",
            "Finished executing code segment: accuracy=79.125, model_size=22042\n",
            "Average accuracy: 77.75, Model size: 22042\n",
            "Evaluating child : \n",
            " # New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 25\n",
            "    nlayer: int = 3\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(5, 1), stride=2, padding=2)\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), stride=1, padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(5, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=50) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = x.reshape(-1, 1, 40)\n",
            "        x = x[..., None]\n",
            "        x = self.conv1(x)\n",
            "        x = self.relu1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 43.62%\n",
            "Epoch 1, Accuracy: 48.12%\n",
            "Epoch 1, Accuracy: 38.88%\n",
            "Epoch 2, Accuracy: 50.75%\n",
            "Epoch 2, Accuracy: 59.12%\n",
            "Epoch 2, Accuracy: 53.00%\n",
            "Epoch 3, Accuracy: 55.50%\n",
            "Epoch 3, Accuracy: 69.12%\n",
            "Epoch 3, Accuracy: 61.00%\n",
            "Epoch 4, Accuracy: 75.12%\n",
            "Epoch 4, Accuracy: 58.75%\n",
            "Epoch 4, Accuracy: 64.00%\n",
            "Epoch 5, Accuracy: 76.88%\n",
            "Epoch 5, Accuracy: 66.00%\n",
            "Epoch 5, Accuracy: 69.25%\n",
            "Epoch 6, Accuracy: 67.62%\n",
            "Epoch 6, Accuracy: 80.25%\n",
            "Epoch 6, Accuracy: 79.00%\n",
            "Epoch 7, Accuracy: 75.25%\n",
            "Epoch 7, Accuracy: 81.00%\n",
            "Epoch 7, Accuracy: 83.62%\n",
            "Epoch 8, Accuracy: 81.12%\n",
            "Epoch 8, Accuracy: 84.62%\n",
            "Epoch 8, Accuracy: 84.62%\n",
            "Epoch 9, Accuracy: 81.00%\n",
            "Epoch 9, Accuracy: 82.62%\n",
            "Epoch 9, Accuracy: 81.75%\n",
            "Epoch 10, Accuracy: 83.62%\n",
            "Final Accuracy: 83.62%, Model Size: 85760\n",
            "Epoch 10, Accuracy: 84.62%\n",
            "Final Accuracy: 84.62%, Model Size: 85760\n",
            "Epoch 10, Accuracy: 84.38%\n",
            "Final Accuracy: 84.38%, Model Size: 85760\n",
            "Epoch 1, Accuracy: 43.38%\n",
            "Epoch 1, Accuracy: 42.25%\n",
            "Epoch 1, Accuracy: 44.12%\n",
            "Epoch 2, Accuracy: 51.00%\n",
            "Epoch 2, Accuracy: 47.00%\n",
            "Epoch 2, Accuracy: 51.62%\n",
            "Epoch 3, Accuracy: 59.75%\n",
            "Epoch 3, Accuracy: 55.38%\n",
            "Epoch 3, Accuracy: 56.00%\n",
            "Epoch 4, Accuracy: 65.62%\n",
            "Epoch 4, Accuracy: 64.75%\n",
            "Epoch 4, Accuracy: 57.12%\n",
            "Epoch 5, Accuracy: 69.88%\n",
            "Epoch 5, Accuracy: 70.25%\n",
            "Epoch 5, Accuracy: 69.25%\n",
            "Epoch 6, Accuracy: 74.50%\n",
            "Epoch 6, Accuracy: 71.50%\n",
            "Epoch 6, Accuracy: 71.75%\n",
            "Epoch 7, Accuracy: 79.00%\n",
            "Epoch 7, Accuracy: 79.25%\n",
            "Epoch 7, Accuracy: 76.25%\n",
            "Epoch 8, Accuracy: 80.12%\n",
            "Epoch 8, Accuracy: 80.38%\n",
            "Epoch 8, Accuracy: 76.62%\n",
            "Epoch 9, Accuracy: 82.88%\n",
            "Epoch 9, Accuracy: 83.75%\n",
            "Epoch 9, Accuracy: 78.25%\n",
            "Epoch 10, Accuracy: 80.38%\n",
            "Finished executing code segment: accuracy=80.375, model_size=85760\n",
            "Epoch 10, Accuracy: 81.88%\n",
            "Finished executing code segment: accuracy=81.875, model_size=85760\n",
            "Epoch 10, Accuracy: 81.00%\n",
            "Finished executing code segment: accuracy=81.0, model_size=85760\n",
            "Average accuracy: 81.08333333333333, Model size: 85760\n",
            "Evaluating child : \n",
            " # New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 30\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=200) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=200, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = x.reshape(-1, 1, 40)\n",
            "        x = x[..., None]\n",
            "        x = self.conv1(x)\n",
            "        x = self.relu1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Epoch 1, Accuracy: 46.00%\n",
            "Epoch 1, Accuracy: 45.50%\n",
            "Epoch 1, Accuracy: 42.62%\n",
            "Epoch 2, Accuracy: 59.88%\n",
            "Epoch 2, Accuracy: 58.88%\n",
            "Epoch 2, Accuracy: 64.62%\n",
            "Epoch 3, Accuracy: 73.00%\n",
            "Epoch 3, Accuracy: 68.12%\n",
            "Epoch 3, Accuracy: 71.25%\n",
            "Epoch 4, Accuracy: 75.75%\n",
            "Epoch 4, Accuracy: 78.50%\n",
            "Epoch 4, Accuracy: 76.25%\n",
            "Epoch 5, Accuracy: 80.38%\n",
            "Epoch 5, Accuracy: 79.50%\n",
            "Epoch 5, Accuracy: 83.25%\n",
            "Epoch 6, Accuracy: 84.12%\n",
            "Epoch 6, Accuracy: 83.62%\n",
            "Epoch 6, Accuracy: 84.38%\n",
            "Epoch 7, Accuracy: 87.25%\n",
            "Epoch 7, Accuracy: 84.25%\n",
            "Epoch 7, Accuracy: 87.25%\n",
            "Epoch 8, Accuracy: 86.25%\n",
            "Epoch 8, Accuracy: 84.12%\n",
            "Epoch 8, Accuracy: 87.75%\n",
            "Epoch 9, Accuracy: 89.38%\n",
            "Epoch 9, Accuracy: 86.88%\n",
            "Epoch 9, Accuracy: 87.75%\n",
            "Epoch 10, Accuracy: 89.25%\n",
            "Final Accuracy: 89.25%, Model Size: 125060\n",
            "Epoch 10, Accuracy: 88.50%\n",
            "Final Accuracy: 88.50%, Model Size: 125060\n",
            "Epoch 10, Accuracy: 82.88%\n",
            "Final Accuracy: 82.88%, Model Size: 125060\n",
            "Epoch 1, Accuracy: 50.12%\n",
            "Epoch 1, Accuracy: 43.88%\n",
            "Epoch 1, Accuracy: 48.75%\n",
            "Epoch 2, Accuracy: 64.62%\n",
            "Epoch 2, Accuracy: 60.12%\n",
            "Epoch 2, Accuracy: 63.75%\n",
            "Epoch 3, Accuracy: 74.50%\n",
            "Epoch 3, Accuracy: 68.38%\n",
            "Epoch 3, Accuracy: 73.50%\n",
            "Epoch 4, Accuracy: 75.88%\n",
            "Epoch 4, Accuracy: 79.88%\n",
            "Epoch 4, Accuracy: 72.75%\n",
            "Epoch 5, Accuracy: 84.50%\n",
            "Epoch 5, Accuracy: 85.75%\n",
            "Epoch 5, Accuracy: 82.00%\n",
            "Epoch 6, Accuracy: 85.50%\n",
            "Epoch 6, Accuracy: 85.75%\n",
            "Epoch 6, Accuracy: 83.62%\n",
            "Epoch 7, Accuracy: 87.00%\n",
            "Epoch 7, Accuracy: 86.25%\n",
            "Epoch 7, Accuracy: 88.38%\n",
            "Epoch 8, Accuracy: 87.88%\n",
            "Epoch 8, Accuracy: 88.25%\n",
            "Epoch 8, Accuracy: 88.62%\n",
            "Epoch 9, Accuracy: 85.62%\n",
            "Epoch 9, Accuracy: 89.75%\n",
            "Epoch 9, Accuracy: 89.62%\n",
            "Epoch 10, Accuracy: 87.62%\n",
            "Finished executing code segment: accuracy=87.625, model_size=125060\n",
            "Epoch 10, Accuracy: 92.38%\n",
            "Finished executing code segment: accuracy=92.375, model_size=125060\n",
            "Epoch 10, Accuracy: 92.25%\n",
            "Finished executing code segment: accuracy=92.25, model_size=125060\n",
            "Average accuracy: 90.75, Model size: 125060\n",
            "top\n",
            "\n",
            "#Seed 1\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "\n",
            "class Seed(nn.Module):\n",
            "    features: int = 32\n",
            "    nlayer: int = 3\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Seed, self).__init__()\n",
            "        # Initialize model parameters here\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "\n",
            "        # Calculate output size dynamically after convolutions\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=256)  # Dynamic input features\n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=256, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        \"\"\"\n",
            "        Calculates the output size after convolutions\n",
            "        \"\"\"\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() # Get output size\n",
            "        return output_size\n",
            "\n",
            "    def __call__(self, x):\n",
            "        x = x.reshape(10, 1, 40)\n",
            "        x = x[..., None]  # Add a channel dimension for 2D convolution\n",
            "        x = self.conv1(x)\n",
            "        # x = self.relu1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "\n",
            "def main():\n",
            "\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "        # print(data)\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "\n",
            "    # Define the split ratio (e.g., 80% train, 20% validation)\n",
            "    train_size = 0.8\n",
            "\n",
            "    # Split the data and labels into training and validation sets\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "\n",
            "    # Create training and validation data in the desired format\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "\n",
            "    # Create the DataLoader\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "\n",
            "    # Create model instance\n",
            "    seed_model = Seed()\n",
            "\n",
            "    # Define loss function and optimizer\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "\n",
            "\n",
            "    optimizer = torch.optim.Adam(seed_model.parameters())\n",
            "\n",
            "    # Train the model\n",
            "    for epoch in range(10):  # Train for 10 epochs\n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            # data = sample[0]\n",
            "            # print(data)\n",
            "            # target = sample[1]\n",
            "\n",
            "            optimizer.zero_grad()\n",
            "            output = seed_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        # Evaluate on test set after each epoch\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = seed_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    # Calculate model size\n",
            "    num_params = sum(p.numel() for p in seed_model.parameters())\n",
            "\n",
            "    return accuracy, num_params\n",
            "\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "\n",
            "{'accuracy': 86.66666666666667, 'model_size': 173002}\n",
            "14993506.666666668\n",
            "# New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 30\n",
            "    nlayer: int = 2\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(3, 1))\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(3, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=200) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=200, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = x.reshape(-1, 1, 40)\n",
            "        x = x[..., None]\n",
            "        x = self.conv1(x)\n",
            "        x = self.relu1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "{'accuracy': 90.75, 'model_size': 125060}\n",
            "11349195.0\n",
            "# New Child Architecture\n",
            "\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torch.utils.data import DataLoader,Dataset\n",
            "from torchvision import datasets, transforms\n",
            "import pickle\n",
            "from sklearn.model_selection import train_test_split\n",
            "import numpy as np\n",
            "\n",
            "class Child(nn.Module):\n",
            "    features: int = 25\n",
            "    nlayer: int = 3\n",
            "\n",
            "    def __init__(self):\n",
            "        super(Child, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.features, kernel_size=(5, 1), stride=2, padding=2)\n",
            "        self.relu1 = nn.ReLU()\n",
            "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1), stride=1, padding=(1, 0))\n",
            "\n",
            "        self.conv_layers = nn.ModuleList()\n",
            "        for _ in range(self.nlayer - 1):\n",
            "            self.conv_layers.append(nn.Conv2d(in_channels=self.features, out_channels=self.features, kernel_size=(5, 1), stride=1, padding='same'))\n",
            "            self.conv_layers.append(nn.ReLU())\n",
            "\n",
            "        self.flatten = nn.Flatten()\n",
            "        self.conv_out_size = self._get_conv_out_size()  \n",
            "        self.fc1 = nn.Linear(in_features=self.conv_out_size[1], out_features=50) \n",
            "        self.relu2 = nn.ReLU()\n",
            "        self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
            "\n",
            "    def _get_conv_out_size(self):\n",
            "        dummy_tensor = torch.randn(1,1,40)\n",
            "        dummy_tensor = dummy_tensor[..., None]\n",
            "        output = self.conv1(dummy_tensor)\n",
            "        output = self.pool1(output)\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            output = conv(output)\n",
            "        output = self.flatten(output)\n",
            "        output_size = output.size() \n",
            "        return output_size\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = x.reshape(-1, 1, 40)\n",
            "        x = x[..., None]\n",
            "        x = self.conv1(x)\n",
            "        x = self.relu1(x)\n",
            "        x = self.pool1(x)\n",
            "\n",
            "        for conv, relu in zip(self.conv_layers[::2], self.conv_layers[1::2]):\n",
            "            x = conv(x)\n",
            "            x = relu(x)\n",
            "\n",
            "        x = self.flatten(x)\n",
            "        x = self.fc1(x)\n",
            "        x = self.relu2(x)\n",
            "        x = self.fc2(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "    with open(\"/content/drive/MyDrive/cmsc733/mnist1d_data.pkl\", \"rb\") as f:\n",
            "          data = pickle.load(f)\n",
            "\n",
            "    x = data['x']\n",
            "    y = data['y']\n",
            "    train_size = 0.8\n",
            "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=1-train_size, random_state=42)\n",
            "    train_dataset = MyDataset(x_train.astype(np.float32), y_train.astype(np.float32))\n",
            "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
            "    val_dataset = MyDataset(x_val.astype(np.float32), y_val.astype(np.float32))\n",
            "    test_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
            "    child_model = Child()\n",
            "    criterion = nn.CrossEntropyLoss()\n",
            "    optimizer = torch.optim.Adam(child_model.parameters())\n",
            "\n",
            "    for epoch in range(10):  \n",
            "        for batch_idx, (data, target) in enumerate(train_loader):\n",
            "            optimizer.zero_grad()\n",
            "            output = child_model(data)\n",
            "            target = target.long()\n",
            "            loss = criterion(output, target)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "\n",
            "        correct = 0\n",
            "        total = 0\n",
            "        with torch.no_grad():\n",
            "            for data, target in test_loader:\n",
            "                output = child_model(data)\n",
            "                _, predicted = torch.max(output.data, 1)\n",
            "                total += target.size(0)\n",
            "                correct += (predicted == target).sum().item()\n",
            "\n",
            "        accuracy = 100 * correct / total\n",
            "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}%\")\n",
            "\n",
            "    num_params = sum(p.numel() for p in child_model.parameters())\n",
            "    return accuracy, num_params\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __init__(self, x, y):\n",
            "        self.x = torch.from_numpy(x)\n",
            "        self.y = torch.from_numpy(y)\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.x)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        return self.x[index], self.y[index]\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy:.2f}%, Model Size: {model_size}\")\n",
            "{'accuracy': 81.08333333333333, 'model_size': 85760}\n",
            "6953706.666666666\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class EvoPrompting:\n",
        "    def __init__(self, lm, task, seed_folder, T, m, k, n, p, alpha,\n",
        "                 n_evaluations, target_model_size, target_accuracy, seed_evaluation=False, evaluation_path=None):\n",
        "        self.seed_folder = seed_folder # Folder where the seed codes are located\n",
        "        self.seed_evaluation = seed_evaluation # Do we have to evaluate the seed codes?\n",
        "        self.pre_evaluated_seed_metrics = self.load_pre_evaluated_seed_metrics(evaluation_path) # Pre evaluated seed metrics\n",
        "        self.lm = lm # the crossover LM\n",
        "        self.temperatures = [0.2, 0.6, 0.8, 1.0] # uniformly sample from these temperaturs\n",
        "        # self.environment = environment # In our case CartPole-v1\n",
        "        self.T = T # Number of rounds\n",
        "        self.m = m # number of few-shot prompts per round\n",
        "        self.n = n # number of samples to generate per prompt,\n",
        "        self.k = k # number of in-context examples per prompt\n",
        "        self.p = p # number of survivors to select per generation\n",
        "        self.n_evaluations = n_evaluations # Number of times to run each model\n",
        "        self.alpha = alpha # the upper threshold for the test error\n",
        "        self.global_population = [] # Global historical Population\n",
        "\n",
        "        self.target_model_size = target_model_size # Target model size of the few shot prompt\n",
        "        self.target_accuracy = target_accuracy # Target number of episodes of the few shot prompt\n",
        "\n",
        "        # Set initial well designed architectures as parent models.\n",
        "        # (Evaluate them useing the same eval function as used in the aalgo)\n",
        "        self.current_population = []\n",
        "        self.initialize_population()\n",
        "\n",
        "\n",
        "    def read_seed_files(self, file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            return file.read()\n",
        "\n",
        "\n",
        "    def load_pre_evaluated_seed_metrics(self, file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            return json.load(file)\n",
        "\n",
        "\n",
        "    def initialize_population(self):\n",
        "        # Initialize the population with seed architectures\n",
        "        # List all the Python files in the seed folder\n",
        "        seed_files = [f for f in os.listdir(self.seed_folder) if f.endswith('.py')]\n",
        "\n",
        "        for seed_file in seed_files:\n",
        "            # print(\"EVALUATING SEED: \", seed_file)\n",
        "            seed_file_path = os.path.join(self.seed_folder, seed_file)\n",
        "            seed_code = self.read_seed_files(seed_file_path)\n",
        "            # print(seed_code.type())\n",
        "            # seed_code = np.array([seed_code1[0],seed_code1[1]])\n",
        "\n",
        "            if self.seed_evaluation:\n",
        "                accuracy, model_size = self.eval_t(seed_code)\n",
        "            else:\n",
        "                json= self.pre_evaluated_seed_metrics[seed_file]\n",
        "                # convert string to float\n",
        "                accuracy = float(json[\"accuracy\"])\n",
        "                model_size = float(json[\"model_size\"])\n",
        "\n",
        "\n",
        "            if(accuracy==0):\n",
        "              print(\"ERROR IN SEED\")\n",
        "              continue\n",
        "            else :\n",
        "              # print(\"EVALUATED SEED: \", seed_file, \"accuracy: \", accuracy, \"model_size: \", model_size)\n",
        "              metrics = {\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"model_size\": model_size,\n",
        "              }\n",
        "\n",
        "              fitness_score = accuracy * model_size\n",
        "              self.global_population.append((seed_code, metrics, fitness_score))\n",
        "              self.current_population.append((seed_code, metrics, fitness_score))\n",
        "\n",
        "\n",
        "    def make_few_shot_prompt(self, in_context_examples):\n",
        "        # Create a few-shot prompt using the in context examples E\n",
        "        min_accuracy = float('inf')\n",
        "        min_model_size = float('inf')\n",
        "        prompt = \"Given below are a few seeds for architecture to run on MNIST-1 dataset. \\\n",
        "        Your job is to generate a new different and improved child architecture based on the seed architectures given.\\\n",
        "        Also keep in mind the dimensions of MNIST-1 data while designing layers for the neural net. If you wish to\\\n",
        "        add a FCN at the end of the network, calculate the expected input shape for the FCN based on the previous layer's\\\n",
        "        output and give that as the no.of weights to the FCN, as shown in Seed 1 and 2.\\\n",
        "        Do not give mismatching size for weights in FCN layer which will lead to an error while running the code.\\\n",
        "        Import data and create data loader in the main function the same way as shown in the seed.\\\n",
        "        Do not forget to reshape data as per pytorch format before feeding it to the network :  x = x.reshape(10, 1, 40).\\\n",
        "        Return accuracy & no.of parameters. Your response\\\n",
        "        should be only text that can be executed by python interpreter and nothing else. Don't include any text like\\\n",
        "        ``` python etc\" # Initialize empty prompt string\n",
        "\n",
        "        for example in in_context_examples:\n",
        "            metrics = example[1]\n",
        "            min_accuracy = min(min_accuracy, metrics['accuracy']) # Retrieve the minium avg episodes of the parent architectures\n",
        "            min_model_size = min(min_model_size, metrics['model_size']) # Retrieve the minium model size of the parent architectures\n",
        "            prompt += f'\\nMetrics : {example[1]}\\n\\n'\n",
        "            prompt += f'\\nCode : {example[0]}\\n\\n'\n",
        "\n",
        "        target_accuracy = min_accuracy * self.target_accuracy\n",
        "        target_model_size = min_model_size * self.target_model_size\n",
        "\n",
        "        prompt+= f'\\nTarget Accuracy : {target_accuracy}\\n\\n'\n",
        "        prompt+= f'\\ntarget_model_size : {target_model_size}\\n\\n'\n",
        "        prompt += f'Code:\\n'\n",
        "        # print(prompt)\n",
        "        return prompt\n",
        "\n",
        "\n",
        "    def generate_child (self, prompt):\n",
        "        child_code = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{'role':'user','content': f'{prompt}'}],\n",
        "            temperature=np.random.choice(self.temperatures, size=1, replace=True).item()\n",
        "            # n=1\n",
        "            # max_tokens = 1000\n",
        "\n",
        "        )\n",
        "        # print(\"child code=\\n\\n \", child_code.choices[0].message['content'])\n",
        "        return child_code.choices[0].message['content']\n",
        "\n",
        "\n",
        "    def eval_t(self, code_segment):\n",
        "\n",
        "        # To execute 'main' from seed\n",
        "        def single_evaluation():\n",
        "            print(\"Executing code segment\")\n",
        "            # print(code_segment)\n",
        "            # print(globals()['main'](self.environment))\n",
        "\n",
        "            try:\n",
        "              exec(code_segment, globals())  # Add globals() here\n",
        "              accuracy, model_size = main()\n",
        "              print(f\"Finished executing code segment: accuracy={accuracy}, model_size={model_size}\")\n",
        "              return accuracy, model_size\n",
        "\n",
        "            except Exception as e:\n",
        "              print(f\"An error occurred: Moving to the next iteration\", e)\n",
        "              return None,0\n",
        "\n",
        "\n",
        "        sum_accuracy = 0\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            print(\"Submitting tasks to the thread pool\")\n",
        "            # count = 1\n",
        "            futures = [executor.submit(single_evaluation) for _ in range(self.n_evaluations)]\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                accuracy, model_size = future.result()\n",
        "                if (accuracy):\n",
        "                  sum_accuracy += accuracy\n",
        "                  # count+=1\n",
        "\n",
        "        avg_accuracy = sum_accuracy / self.n_evaluations\n",
        "        print(f\"Average accuracy: {avg_accuracy}, Model size: {model_size}\")\n",
        "        return avg_accuracy, model_size\n",
        "\n",
        "\n",
        "    def get_top(self, global_population):\n",
        "        \"\"\"\n",
        "        Returns the top entries from the global_population based on their fitness scores.\n",
        "\n",
        "        This function takes a list of global_population entries, where each entry is a tuple containing:\n",
        "        (code, metadata, fitness_score). It sorts the entries based on their fitness scores in descending\n",
        "        order and returns the top num_top entries.\n",
        "\n",
        "        Parameters:\n",
        "        global_population (list): A list of tuples, where each tuple represents an entry in the global\n",
        "                                population, containing (code, metadata, fitness_score).\n",
        "        num_top (int, optional): The number of top entries to return. Defaults to 5.\n",
        "\n",
        "        Returns:\n",
        "        list: A list containing the top num_top entries from the global_population based on their fitness\n",
        "            scores.\n",
        "        \"\"\"\n",
        "        sorted_population = sorted(global_population, key=lambda x: x[2], reverse=True)\n",
        "        top_entries = sorted_population[:self.p]\n",
        "        return top_entries\n",
        "\n",
        "\n",
        "    def cross_mutation(self):\n",
        "        child_architectures = [] # C is the set of architectures of length k\n",
        "        for _ in range(self.m): # create m number of few shot prompts\n",
        "            in_context_examples = random.sample(self.current_population, self.k) # Pick k amount of parents from P\n",
        "\n",
        "            # in_context_examples = random.sample(self.global_population, self.k)\n",
        "\n",
        "            prompt = self.make_few_shot_prompt(in_context_examples)\n",
        "            Ci = [self.generate_child(prompt) for _ in range(self.n)]\n",
        "            child_architectures.extend(Ci)\n",
        "        return child_architectures\n",
        "\n",
        "\n",
        "    def fitness_function(self, model_size, accuracy):\n",
        "        if(model_size):\n",
        "          return model_size * accuracy\n",
        "        else :\n",
        "          return 0\n",
        "\n",
        "\n",
        "    def filter_and_eval(self, child_architectures, alpha):\n",
        "        CEVALED = []\n",
        "        for code_segment in child_architectures:\n",
        "            print(\"Evaluating child : \\n\", code_segment)\n",
        "            avg_accuracy, model_size = self.eval_t(code_segment)\n",
        "            if avg_accuracy!=0 :\n",
        "              if avg_accuracy < alpha : # filter out the bad models\n",
        "                  metrics = {\n",
        "                      \"accuracy\": avg_accuracy,\n",
        "                      \"model_size\": model_size,\n",
        "                  }\n",
        "                  fitness_score = self.fitness_function(model_size, avg_accuracy)\n",
        "                  CEVALED.append((code_segment, metrics, fitness_score))\n",
        "            else :\n",
        "              print(\"Error in child code generated by the GPT\")\n",
        "        return CEVALED\n",
        "\n",
        "\n",
        "    def train(self, CEVALED):\n",
        "        # The original author of the paper proposes a soft prompt tune method here\n",
        "        # I need a model here that can be soft promt tuned, probably gpt2 on huggingface.\n",
        "        pass\n",
        "\n",
        "    def evolve(self):\n",
        "        t = 0\n",
        "        while t < self.T: # number of evoluationary rounds\n",
        "            child_architectures = self.cross_mutation() # Generate the set of code samples\n",
        "            # print(\"Evaluating the following child architectures : \")\n",
        "            # print(child_architectures)\n",
        "            evaluated_children = self.filter_and_eval(child_architectures, self.alpha)\n",
        "            if len(evaluated_children) > 0:\n",
        "              self.global_population.extend(evaluated_children)\n",
        "\n",
        "            if t < self.T - 1:\n",
        "                self.current_population = self.get_top(global_population=self.global_population)\n",
        "                #run without training\n",
        "                #self.lm = self.train(self.lm, [c for c, _ in evaluated_children if c not in self.current_population])\n",
        "\n",
        "            t += 1\n",
        "\n",
        "        return self.get_top(global_population=self.global_population)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the EvoPrompting class\n",
        "    T = 10 # Number of rounds\n",
        "    m = 1 # number of few-shot prompts per round\n",
        "    n = 1 # number of samples to generate per prompt,\n",
        "    k = 3 # number of in-context examples per prompt\n",
        "    p = 3 # number of survivors to select per generation\n",
        "    n_evaluations = 3 # Number of times to run each model\n",
        "    alpha = 96 # TBD (cutoff accuracy for evaluated children)\n",
        "    task = \"create a solution that genreates the best model with the smallest paramter size\"\n",
        "    # environment = \"CartPole-v1\" # environment of the task\n",
        "    seed_folder = \"/mnist1d/seeds\" # Folder which contains al the initial seed architectures\n",
        "    lm = \"gpt-3.5-turbo\" # Language model to use for prompt generation\n",
        "\n",
        "    target_model_factor = 0.90\n",
        "    target_episodes = 0.95\n",
        "\n",
        "    evo_prompt = EvoPrompting(lm, task, seed_folder, T, m, k, n, p, alpha,\n",
        "                              n_evaluations, target_model_factor, target_episodes, seed_evaluation=True,\n",
        "                              evaluation_path=\"\")\n",
        "    # Run the main evolutionary loop\n",
        "    evo_prompt.evolve()\n",
        "\n",
        "    # evo_prompt.initialize_population()\n",
        "    # print(\"evorpompt Global Population: \", evo_prompt.global_population)\n",
        "\n",
        "    top = evo_prompt.get_top(global_population = evo_prompt.global_population)\n",
        "\n",
        "    print('top\\n')\n",
        "    for code in top :\n",
        "      for i in code :\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJKhcfdgEnnp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62eX4x2LC7Xn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
