{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYufW9Okyjv9",
        "outputId": "a7b4d893-9acd-4c97-9c38-d88a93657737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/cmsc733/evoprompt_cifar\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "FOLDERNAME = '/evoprompt_cifar'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXxUxI1V2WCi",
        "outputId": "02b97ef6-1c33-4b37-c551-842b2f5d03f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "\n",
        "import concurrent.futures\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import openai\n",
        "# import torch\n",
        "# from torch.utils.data import DataLoader,Dataset\n",
        "# from torchvision import datasets, transforms\n",
        "\n",
        "#Enter your api key\n",
        "openai.api_key = ''\n",
        "# pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4-yARLs2YOh",
        "outputId": "faf2360f-a0f9-436f-9ac3-b7afb71911ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Iteration 0, Epoch 1, Loss: 3.585379123687744, Accuracy: 7.8125, Val Loss: 6.301713943481445, Val Accuracy: 13.09999942779541\n",
            "Iteration 0, Epoch 1, Loss: 3.530014991760254, Accuracy: 7.8125, Val Loss: 18.751785278320312, Val Accuracy: 8.0\n",
            "Iteration 700, Epoch 1, Loss: 1.4140808582305908, Accuracy: 50.73332977294922, Val Loss: 1.1524512767791748, Val Accuracy: 60.000003814697266\n",
            "Iteration 700, Epoch 1, Loss: 1.789637804031372, Accuracy: 38.20880889892578, Val Loss: 1.4623537063598633, Val Accuracy: 47.20000076293945\n",
            "Iteration 1400, Epoch 2, Loss: 1.0196714401245117, Accuracy: 64.8277587890625, Val Loss: 1.0305410623550415, Val Accuracy: 65.69999694824219\n",
            "Iteration 1400, Epoch 2, Loss: 1.3861662149429321, Accuracy: 50.28050994873047, Val Loss: 1.3331040143966675, Val Accuracy: 52.39999771118164\n",
            "Iteration 2100, Epoch 3, Loss: 0.8919765949249268, Accuracy: 69.53811645507812, Val Loss: 1.0307246446609497, Val Accuracy: 65.80000305175781\n",
            "Iteration 2100, Epoch 3, Loss: 1.2794328927993774, Accuracy: 54.18222427368164, Val Loss: 1.320055603981018, Val Accuracy: 54.400001525878906\n",
            "Iteration 2800, Epoch 4, Loss: 0.8076736927032471, Accuracy: 72.19496154785156, Val Loss: 0.9823405146598816, Val Accuracy: 68.0\n",
            "Iteration 2800, Epoch 4, Loss: 1.2130712270736694, Accuracy: 56.666255950927734, Val Loss: 1.2323620319366455, Val Accuracy: 55.0\n",
            "Iteration 3500, Epoch 5, Loss: 0.741790771484375, Accuracy: 74.36713409423828, Val Loss: 1.0250762701034546, Val Accuracy: 68.0\n",
            "Iteration 3500, Epoch 5, Loss: 1.1775041818618774, Accuracy: 57.926918029785156, Val Loss: 1.2207812070846558, Val Accuracy: 55.69999694824219\n",
            "Iteration 4200, Epoch 6, Loss: 0.6953373551368713, Accuracy: 75.92655181884766, Val Loss: 0.9348375797271729, Val Accuracy: 69.30000305175781\n",
            "Iteration 4200, Epoch 6, Loss: 1.1424144506454468, Accuracy: 59.282344818115234, Val Loss: 1.1489877700805664, Val Accuracy: 59.500003814697266\n",
            "Iteration 4900, Epoch 7, Loss: 0.6411131620407104, Accuracy: 77.57684326171875, Val Loss: 1.035179853439331, Val Accuracy: 66.5\n",
            "Iteration 4900, Epoch 7, Loss: 1.1077473163604736, Accuracy: 60.72745895385742, Val Loss: 1.1734561920166016, Val Accuracy: 59.20000076293945\n",
            "Iteration 5600, Epoch 8, Loss: 0.5957427024841309, Accuracy: 79.27562713623047, Val Loss: 1.0143983364105225, Val Accuracy: 67.5\n",
            "Iteration 5600, Epoch 8, Loss: 1.0764482021331787, Accuracy: 61.80046844482422, Val Loss: 1.0878064632415771, Val Accuracy: 60.60000228881836\n",
            "Iteration 6300, Epoch 9, Loss: 0.552212655544281, Accuracy: 80.70809173583984, Val Loss: 1.0985198020935059, Val Accuracy: 66.5999984741211\n",
            "Iteration 6300, Epoch 9, Loss: 1.0424193143844604, Accuracy: 63.00578308105469, Val Loss: 1.1457759141921997, Val Accuracy: 61.79999542236328\n",
            "Iteration 7000, Epoch 10, Loss: 0.503016471862793, Accuracy: 82.87091064453125, Val Loss: 1.0701913833618164, Val Accuracy: 67.5\n",
            "Iteration 7000, Epoch 10, Loss: 1.019152283668518, Accuracy: 63.361568450927734, Val Loss: 1.1535650491714478, Val Accuracy: 61.69999694824219\n",
            "Final Accuracy: 61.69999837875366%, Model Size: 822510\n",
            "Final Accuracy: 67.5000011920929%, Model Size: 156910\n",
            "Iteration 0, Epoch 1, Loss: 3.937450647354126, Accuracy: 3.125, Val Loss: 4.8851318359375, Val Accuracy: 12.800000190734863\n",
            "Iteration 0, Epoch 1, Loss: 2.9142327308654785, Accuracy: 20.3125, Val Loss: 13.286602020263672, Val Accuracy: 12.700000762939453\n",
            "Iteration 700, Epoch 1, Loss: 1.4498686790466309, Accuracy: 49.193115234375, Val Loss: 1.1776827573776245, Val Accuracy: 58.499996185302734\n",
            "Iteration 700, Epoch 1, Loss: 1.5439475774765015, Accuracy: 47.2004280090332, Val Loss: 1.2808328866958618, Val Accuracy: 55.599998474121094\n",
            "Iteration 1400, Epoch 2, Loss: 1.1833494901657104, Accuracy: 58.4670295715332, Val Loss: 1.1628639698028564, Val Accuracy: 57.900001525878906\n",
            "Iteration 1400, Epoch 2, Loss: 1.0744353532791138, Accuracy: 62.46800994873047, Val Loss: 1.0473512411117554, Val Accuracy: 63.099998474121094\n",
            "Iteration 2100, Epoch 3, Loss: 1.0755798816680908, Accuracy: 62.19793701171875, Val Loss: 1.1305712461471558, Val Accuracy: 62.400001525878906\n",
            "Iteration 2100, Epoch 3, Loss: 0.9517731070518494, Accuracy: 66.89092254638672, Val Loss: 0.9986533522605896, Val Accuracy: 65.4000015258789\n",
            "Iteration 2800, Epoch 4, Loss: 1.013375163078308, Accuracy: 64.60610961914062, Val Loss: 1.077252745628357, Val Accuracy: 62.19999694824219\n",
            "Iteration 2800, Epoch 4, Loss: 0.8731011748313904, Accuracy: 69.69744110107422, Val Loss: 0.9962018132209778, Val Accuracy: 65.5\n",
            "Iteration 3500, Epoch 5, Loss: 0.9722189903259277, Accuracy: 66.06121063232422, Val Loss: 1.0985900163650513, Val Accuracy: 63.599998474121094\n",
            "Iteration 3500, Epoch 5, Loss: 0.8143563270568848, Accuracy: 71.83924102783203, Val Loss: 0.9575525522232056, Val Accuracy: 68.5\n",
            "Iteration 4200, Epoch 6, Loss: 0.9449582695960999, Accuracy: 67.21697998046875, Val Loss: 1.071489691734314, Val Accuracy: 63.900001525878906\n",
            "Iteration 4200, Epoch 6, Loss: 0.7687399983406067, Accuracy: 73.33642578125, Val Loss: 0.9430244565010071, Val Accuracy: 68.5\n",
            "Iteration 4900, Epoch 7, Loss: 0.9165322184562683, Accuracy: 68.02254486083984, Val Loss: 1.1733834743499756, Val Accuracy: 59.79999923706055\n",
            "Iteration 4900, Epoch 7, Loss: 0.7265676856040955, Accuracy: 74.93852233886719, Val Loss: 0.9777860045433044, Val Accuracy: 68.0999984741211\n",
            "Iteration 5600, Epoch 8, Loss: 0.8965824842453003, Accuracy: 68.87421417236328, Val Loss: 1.0392330884933472, Val Accuracy: 63.900001525878906\n",
            "Iteration 5600, Epoch 8, Loss: 0.6898170113563538, Accuracy: 76.21600341796875, Val Loss: 0.9207788705825806, Val Accuracy: 69.0999984741211\n",
            "Iteration 6300, Epoch 9, Loss: 0.8610086441040039, Accuracy: 70.1499252319336, Val Loss: 1.0622129440307617, Val Accuracy: 63.20000457763672\n",
            "Iteration 6300, Epoch 9, Loss: 0.6533588767051697, Accuracy: 77.29407501220703, Val Loss: 0.9834051728248596, Val Accuracy: 67.69999694824219\n",
            "Iteration 7000, Epoch 10, Loss: 0.8380028009414673, Accuracy: 70.89661407470703, Val Loss: 1.0220259428024292, Val Accuracy: 64.4000015258789\n",
            "Iteration 7000, Epoch 10, Loss: 0.6063094139099121, Accuracy: 79.24942016601562, Val Loss: 1.0053255558013916, Val Accuracy: 69.0999984741211\n",
            "Finished executing code segment: accuracy=64.3999993801117, model_size=1025110\n",
            "Finished executing code segment: accuracy=69.0999984741211, model_size=130150\n",
            "Average accuracy: 66.7499989271164, Model size: 130150\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Iteration 0, Epoch 1, Loss: 3.0779404640197754, Accuracy: 1.5625, Val Loss: 84.24749755859375, Val Accuracy: 14.100000381469727\n",
            "Iteration 0, Epoch 1, Loss: 3.1747708320617676, Accuracy: 6.25, Val Loss: 119.16425323486328, Val Accuracy: 9.600000381469727\n",
            "Iteration 700, Epoch 1, Loss: 1.9729242324829102, Accuracy: 37.52451705932617, Val Loss: 1.5757211446762085, Val Accuracy: 47.29999923706055\n",
            "Iteration 700, Epoch 1, Loss: 2.348259210586548, Accuracy: 42.39479446411133, Val Loss: 1.3812282085418701, Val Accuracy: 52.20000076293945\n",
            "Iteration 1400, Epoch 2, Loss: 1.4774829149246216, Accuracy: 47.36712646484375, Val Loss: 1.5108511447906494, Val Accuracy: 46.70000076293945\n",
            "Iteration 1400, Epoch 2, Loss: 1.1696810722351074, Accuracy: 59.17322540283203, Val Loss: 1.2375297546386719, Val Accuracy: 58.499996185302734\n",
            "Iteration 2100, Epoch 3, Loss: 1.3868719339370728, Accuracy: 50.58765411376953, Val Loss: 1.5191388130187988, Val Accuracy: 48.10000228881836\n",
            "Iteration 2100, Epoch 3, Loss: 0.8439743518829346, Accuracy: 71.11160278320312, Val Loss: 1.264308214187622, Val Accuracy: 58.70000076293945\n",
            "Iteration 2800, Epoch 4, Loss: 1.3306093215942383, Accuracy: 52.833003997802734, Val Loss: 1.4853949546813965, Val Accuracy: 45.599998474121094\n",
            "Iteration 2800, Epoch 4, Loss: 0.535735011100769, Accuracy: 81.93339538574219, Val Loss: 1.6956437826156616, Val Accuracy: 54.400001525878906\n",
            "Iteration 3500, Epoch 5, Loss: 1.2904834747314453, Accuracy: 54.183353424072266, Val Loss: 1.4907617568969727, Val Accuracy: 49.70000076293945\n",
            "Iteration 3500, Epoch 5, Loss: 0.3384537100791931, Accuracy: 88.43321228027344, Val Loss: 1.9534916877746582, Val Accuracy: 57.30000305175781\n",
            "Iteration 4200, Epoch 6, Loss: 1.2622056007385254, Accuracy: 55.416107177734375, Val Loss: 1.4451985359191895, Val Accuracy: 50.80000305175781\n",
            "Iteration 4200, Epoch 6, Loss: 0.2337462455034256, Accuracy: 92.1285400390625, Val Loss: 1.9853819608688354, Val Accuracy: 58.70000076293945\n",
            "Iteration 4900, Epoch 7, Loss: 1.2338179349899292, Accuracy: 56.34221267700195, Val Loss: 1.4480985403060913, Val Accuracy: 47.900001525878906\n",
            "Iteration 4900, Epoch 7, Loss: 0.16328808665275574, Accuracy: 94.68238067626953, Val Loss: 2.4033150672912598, Val Accuracy: 54.599998474121094\n",
            "Iteration 5600, Epoch 8, Loss: 1.2134160995483398, Accuracy: 57.0018310546875, Val Loss: 1.4545881748199463, Val Accuracy: 49.099998474121094\n",
            "Iteration 5600, Epoch 8, Loss: 0.12145663052797318, Accuracy: 95.99895477294922, Val Loss: 2.4014499187469482, Val Accuracy: 59.29999923706055\n",
            "Iteration 6300, Epoch 9, Loss: 1.1903263330459595, Accuracy: 57.91184997558594, Val Loss: 1.4626338481903076, Val Accuracy: 48.89999771118164\n",
            "Iteration 6300, Epoch 9, Loss: 0.11039037257432938, Accuracy: 96.58598327636719, Val Loss: 2.7342803478240967, Val Accuracy: 58.89999771118164\n",
            "Iteration 7000, Epoch 10, Loss: 1.1723648309707642, Accuracy: 58.48422622680664, Val Loss: 1.4829400777816772, Val Accuracy: 49.39999771118164\n",
            "Iteration 7000, Epoch 10, Loss: 0.10253819078207016, Accuracy: 96.80198669433594, Val Loss: 3.300102949142456, Val Accuracy: 56.900001525878906\n",
            "Final Accuracy: 49.39999878406525%, Model Size: 3218698\n",
            "Final Accuracy: 56.90000057220459%, Model Size: 2774026\n",
            "Iteration 0, Epoch 1, Loss: 3.4458041191101074, Accuracy: 9.375, Val Loss: 91.82862854003906, Val Accuracy: 15.000000953674316\n",
            "Iteration 0, Epoch 1, Loss: 2.9352505207061768, Accuracy: 4.6875, Val Loss: 51.13115692138672, Val Accuracy: 8.800000190734863\n",
            "Iteration 700, Epoch 1, Loss: 2.218903064727783, Accuracy: 44.94472122192383, Val Loss: 1.3738048076629639, Val Accuracy: 51.70000076293945\n",
            "Iteration 700, Epoch 1, Loss: 1.9514201879501343, Accuracy: 42.606544494628906, Val Loss: 1.3918989896774292, Val Accuracy: 52.20000076293945\n",
            "Iteration 1400, Epoch 2, Loss: 1.1509572267532349, Accuracy: 59.89419174194336, Val Loss: 1.1808199882507324, Val Accuracy: 58.29999923706055\n",
            "Iteration 1400, Epoch 2, Loss: 1.1742749214172363, Accuracy: 59.18552780151367, Val Loss: 1.2654008865356445, Val Accuracy: 57.20000457763672\n",
            "Iteration 2100, Epoch 3, Loss: 0.8659396171569824, Accuracy: 70.07908630371094, Val Loss: 1.2654074430465698, Val Accuracy: 61.29999923706055\n",
            "Iteration 2100, Epoch 3, Loss: 0.9297678470611572, Accuracy: 68.34358215332031, Val Loss: 1.253154993057251, Val Accuracy: 59.89999771118164\n",
            "Iteration 2800, Epoch 4, Loss: 0.5864204168319702, Accuracy: 80.0540542602539, Val Loss: 1.4627671241760254, Val Accuracy: 58.70000076293945\n",
            "Iteration 2800, Epoch 4, Loss: 0.692912220954895, Accuracy: 76.472412109375, Val Loss: 1.3830559253692627, Val Accuracy: 58.70000076293945\n",
            "Iteration 3500, Epoch 5, Loss: 0.3661775290966034, Accuracy: 87.63587188720703, Val Loss: 1.7043818235397339, Val Accuracy: 58.0\n",
            "Iteration 3500, Epoch 5, Loss: 0.4625760316848755, Accuracy: 84.57523345947266, Val Loss: 1.8452684879302979, Val Accuracy: 55.900001525878906\n",
            "Iteration 4200, Epoch 6, Loss: 0.2572175860404968, Accuracy: 91.05036926269531, Val Loss: 2.0120432376861572, Val Accuracy: 59.29999923706055\n",
            "Iteration 4200, Epoch 6, Loss: 0.3071937561035156, Accuracy: 89.44575500488281, Val Loss: 1.8659515380859375, Val Accuracy: 57.30000305175781\n",
            "Iteration 4900, Epoch 7, Loss: 0.1879451721906662, Accuracy: 93.48873138427734, Val Loss: 2.0911741256713867, Val Accuracy: 57.79999923706055\n",
            "Iteration 4900, Epoch 7, Loss: 0.21248158812522888, Accuracy: 92.52049255371094, Val Loss: 2.3091979026794434, Val Accuracy: 56.69999694824219\n",
            "Iteration 5600, Epoch 8, Loss: 0.12499300390481949, Accuracy: 95.88127899169922, Val Loss: 2.410665988922119, Val Accuracy: 56.5\n",
            "Iteration 5600, Epoch 8, Loss: 0.13340117037296295, Accuracy: 95.27327728271484, Val Loss: 2.9057562351226807, Val Accuracy: 53.60000228881836\n",
            "Iteration 6300, Epoch 9, Loss: 0.1071154847741127, Accuracy: 96.36019134521484, Val Loss: 2.839857339859009, Val Accuracy: 57.20000457763672\n",
            "Iteration 6300, Epoch 9, Loss: 0.09651155769824982, Accuracy: 96.79370880126953, Val Loss: 2.6586170196533203, Val Accuracy: 56.80000305175781\n",
            "Iteration 7000, Epoch 10, Loss: 0.1118054911494255, Accuracy: 96.0864486694336, Val Loss: 2.9157626628875732, Val Accuracy: 58.60000228881836\n",
            "Iteration 7000, Epoch 10, Loss: 0.06556999683380127, Accuracy: 98.02862548828125, Val Loss: 3.0786399841308594, Val Accuracy: 57.70000076293945\n",
            "Finished executing code segment: accuracy=58.60000252723694, model_size=2774026\n",
            "Finished executing code segment: accuracy=57.70000219345093, model_size=1386378\n",
            "Average accuracy: 58.15000236034393, Model size: 1386378\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Iteration 0, Epoch 1, Loss: 2.950732946395874, Accuracy: 12.5, Val Loss: 14.035383224487305, Val Accuracy: 11.90000057220459\n",
            "Iteration 0, Epoch 1, Loss: 3.1741771697998047, Accuracy: 10.9375, Val Loss: 8.406553268432617, Val Accuracy: 12.700000762939453\n",
            "Iteration 700, Epoch 1, Loss: 2.403057098388672, Accuracy: 42.374732971191406, Val Loss: 1.5974756479263306, Val Accuracy: 52.39999771118164\n",
            "Iteration 700, Epoch 1, Loss: 1.9606150388717651, Accuracy: 42.53076171875, Val Loss: 1.624779224395752, Val Accuracy: 49.70000076293945\n",
            "Iteration 1400, Epoch 2, Loss: 1.3688992261886597, Accuracy: 57.00049591064453, Val Loss: 1.2585933208465576, Val Accuracy: 60.10000228881836\n",
            "Iteration 1400, Epoch 2, Loss: 1.3034186363220215, Accuracy: 56.601871490478516, Val Loss: 1.2056807279586792, Val Accuracy: 58.60000228881836\n",
            "Iteration 2100, Epoch 3, Loss: 1.093215823173523, Accuracy: 63.38971710205078, Val Loss: 1.1298657655715942, Val Accuracy: 63.599998474121094\n",
            "Iteration 2100, Epoch 3, Loss: 1.1186349391937256, Accuracy: 62.04690170288086, Val Loss: 1.09994375705719, Val Accuracy: 61.400001525878906\n",
            "Iteration 2800, Epoch 4, Loss: 0.9816444516181946, Accuracy: 67.03528594970703, Val Loss: 1.0727500915527344, Val Accuracy: 63.80000305175781\n",
            "Iteration 2800, Epoch 4, Loss: 1.0255919694900513, Accuracy: 65.2025375366211, Val Loss: 1.0942097902297974, Val Accuracy: 63.20000457763672\n",
            "Iteration 3500, Epoch 5, Loss: 0.9243815541267395, Accuracy: 68.90374755859375, Val Loss: 1.0821048021316528, Val Accuracy: 66.0\n",
            "Iteration 3500, Epoch 5, Loss: 0.9755133390426636, Accuracy: 67.02302551269531, Val Loss: 1.0851237773895264, Val Accuracy: 65.5\n",
            "Iteration 4200, Epoch 6, Loss: 0.875555157661438, Accuracy: 70.32513427734375, Val Loss: 1.0456516742706299, Val Accuracy: 65.20000457763672\n",
            "Iteration 4200, Epoch 6, Loss: 0.9358278512954712, Accuracy: 68.1351089477539, Val Loss: 1.0737545490264893, Val Accuracy: 64.60000610351562\n",
            "Iteration 4900, Epoch 7, Loss: 0.8327221274375916, Accuracy: 71.89549255371094, Val Loss: 1.106773853302002, Val Accuracy: 64.80000305175781\n",
            "Iteration 4900, Epoch 7, Loss: 0.8949763774871826, Accuracy: 69.23155975341797, Val Loss: 1.1120635271072388, Val Accuracy: 62.80000305175781\n",
            "Iteration 5600, Epoch 8, Loss: 0.7864437103271484, Accuracy: 73.05831146240234, Val Loss: 1.070316195487976, Val Accuracy: 65.4000015258789\n",
            "Iteration 5600, Epoch 8, Loss: 0.8470911383628845, Accuracy: 70.60669708251953, Val Loss: 1.057828426361084, Val Accuracy: 67.0\n",
            "An error occurred: Moving to the next iteration {{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Expected multiples argument to be a vector of length 0 but got length 1 [Op:Tile] name: \n",
            "Iteration 6300, Epoch 9, Loss: 0.8237432837486267, Accuracy: 71.56791687011719, Val Loss: 1.0829018354415894, Val Accuracy: 64.80000305175781\n",
            "Iteration 7000, Epoch 10, Loss: 0.7923389077186584, Accuracy: 72.4299087524414, Val Loss: 1.0701254606246948, Val Accuracy: 65.5\n",
            "Final Accuracy: 65.49999713897705%, Model Size: 162730\n",
            "Iteration 0, Epoch 1, Loss: 2.96197509765625, Accuracy: 14.0625, Val Loss: 4.315437316894531, Val Accuracy: 9.700000762939453\n",
            "Iteration 700, Epoch 1, Loss: 1.7586371898651123, Accuracy: 43.14149475097656, Val Loss: 1.4244587421417236, Val Accuracy: 52.999996185302734\n",
            "Iteration 1400, Epoch 2, Loss: 1.2845443487167358, Accuracy: 55.824310302734375, Val Loss: 1.2356168031692505, Val Accuracy: 58.499996185302734\n",
            "Iteration 2100, Epoch 3, Loss: 1.1286579370498657, Accuracy: 61.19837188720703, Val Loss: 1.1505030393600464, Val Accuracy: 60.60000228881836\n",
            "Iteration 2800, Epoch 4, Loss: 1.055228352546692, Accuracy: 63.80156326293945, Val Loss: 1.145455241203308, Val Accuracy: 60.5\n",
            "Iteration 3500, Epoch 5, Loss: 1.0164477825164795, Accuracy: 65.24242401123047, Val Loss: 1.110398769378662, Val Accuracy: 62.80000305175781\n",
            "Iteration 4200, Epoch 6, Loss: 0.9874139428138733, Accuracy: 66.1809310913086, Val Loss: 1.1053236722946167, Val Accuracy: 63.0\n",
            "Iteration 4900, Epoch 7, Loss: 0.9553230404853821, Accuracy: 67.22848510742188, Val Loss: 1.1253730058670044, Val Accuracy: 63.80000305175781\n",
            "Iteration 5600, Epoch 8, Loss: 0.9365431070327759, Accuracy: 67.82819366455078, Val Loss: 1.1077224016189575, Val Accuracy: 62.69999694824219\n",
            "Iteration 6300, Epoch 9, Loss: 0.9118448495864868, Accuracy: 68.722900390625, Val Loss: 1.120620846748352, Val Accuracy: 64.0999984741211\n",
            "Iteration 7000, Epoch 10, Loss: 0.8960721492767334, Accuracy: 68.95443725585938, Val Loss: 1.1059632301330566, Val Accuracy: 64.0999984741211\n",
            "Finished executing code segment: accuracy=64.0999972820282, model_size=77770\n",
            "Average accuracy: 32.0499986410141, Model size: 77770\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Iteration 0, Epoch 1, Loss: 2.9285929203033447, Accuracy: 20.3125, Val Loss: 13.746129035949707, Val Accuracy: 13.500000953674316\n",
            "Iteration 0, Epoch 1, Loss: 3.245482921600342, Accuracy: 14.0625, Val Loss: 8.93539047241211, Val Accuracy: 8.699999809265137\n",
            "Iteration 700, Epoch 1, Loss: 1.784898042678833, Accuracy: 37.37071990966797, Val Loss: 1.566576361656189, Val Accuracy: 44.400001525878906\n",
            "Iteration 700, Epoch 1, Loss: 1.6078357696533203, Accuracy: 43.19498825073242, Val Loss: 1.4154448509216309, Val Accuracy: 50.80000305175781\n",
            "Iteration 1400, Epoch 2, Loss: 1.4751256704330444, Accuracy: 47.60826873779297, Val Loss: 1.4515396356582642, Val Accuracy: 50.0\n",
            "Iteration 1400, Epoch 2, Loss: 1.2873423099517822, Accuracy: 55.02460479736328, Val Loss: 1.279559850692749, Val Accuracy: 56.599998474121094\n",
            "Iteration 2100, Epoch 3, Loss: 1.3720742464065552, Accuracy: 51.425193786621094, Val Loss: 1.3923516273498535, Val Accuracy: 52.0\n",
            "Iteration 2100, Epoch 3, Loss: 1.178769588470459, Accuracy: 59.10314178466797, Val Loss: 1.2528767585754395, Val Accuracy: 58.0\n",
            "Iteration 2800, Epoch 4, Loss: 1.3094910383224487, Accuracy: 53.848785400390625, Val Loss: 1.391775369644165, Val Accuracy: 51.099998474121094\n",
            "Iteration 2800, Epoch 4, Loss: 1.1098394393920898, Accuracy: 61.28230667114258, Val Loss: 1.173987627029419, Val Accuracy: 61.0\n",
            "Iteration 3500, Epoch 5, Loss: 1.267732858657837, Accuracy: 55.07365417480469, Val Loss: 1.3754345178604126, Val Accuracy: 52.29999923706055\n",
            "Iteration 3500, Epoch 5, Loss: 1.0578175783157349, Accuracy: 63.200801849365234, Val Loss: 1.1699228286743164, Val Accuracy: 60.60000228881836\n",
            "Iteration 4200, Epoch 6, Loss: 1.238163709640503, Accuracy: 56.132080078125, Val Loss: 1.3106971979141235, Val Accuracy: 54.79999923706055\n",
            "Iteration 4200, Epoch 6, Loss: 1.0200031995773315, Accuracy: 64.36573028564453, Val Loss: 1.1618252992630005, Val Accuracy: 60.20000076293945\n",
            "Iteration 4900, Epoch 7, Loss: 1.2196496725082397, Accuracy: 56.670082092285156, Val Loss: 1.3030606508255005, Val Accuracy: 54.20000076293945\n",
            "Iteration 4900, Epoch 7, Loss: 0.9847774505615234, Accuracy: 65.69159698486328, Val Loss: 1.2081990242004395, Val Accuracy: 59.20000076293945\n",
            "Iteration 5600, Epoch 8, Loss: 1.1923739910125732, Accuracy: 57.550994873046875, Val Loss: 1.3265538215637207, Val Accuracy: 53.10000228881836\n",
            "Iteration 5600, Epoch 8, Loss: 0.9512295126914978, Accuracy: 66.78870391845703, Val Loss: 1.1229302883148193, Val Accuracy: 60.10000228881836\n",
            "Iteration 6300, Epoch 9, Loss: 1.1739518642425537, Accuracy: 58.08345031738281, Val Loss: 1.355685830116272, Val Accuracy: 54.5\n",
            "Iteration 6300, Epoch 9, Loss: 0.9156036972999573, Accuracy: 67.94617462158203, Val Loss: 1.2031978368759155, Val Accuracy: 59.39999771118164\n",
            "Iteration 7000, Epoch 10, Loss: 1.156860589981079, Accuracy: 59.12675094604492, Val Loss: 1.3558157682418823, Val Accuracy: 54.10000228881836\n",
            "Iteration 7000, Epoch 10, Loss: 0.8840065598487854, Accuracy: 69.02745056152344, Val Loss: 1.253769874572754, Val Accuracy: 58.29999923706055\n",
            "Final Accuracy: 54.100000858306885%, Model Size: 580682\n",
            "Final Accuracy: 58.30000042915344%, Model Size: 318538\n",
            "Iteration 0, Epoch 1, Loss: 3.1871860027313232, Accuracy: 6.25, Val Loss: 11.518308639526367, Val Accuracy: 12.399999618530273\n",
            "Iteration 0, Epoch 1, Loss: 3.6290082931518555, Accuracy: 7.8125, Val Loss: 6.093746185302734, Val Accuracy: 10.0\n",
            "Iteration 700, Epoch 1, Loss: 1.3968851566314697, Accuracy: 53.33452224731445, Val Loss: 1.1017570495605469, Val Accuracy: 60.900001525878906\n",
            "Iteration 700, Epoch 1, Loss: 1.5559132099151611, Accuracy: 44.84218978881836, Val Loss: 1.3121960163116455, Val Accuracy: 53.79999923706055\n",
            "Iteration 1400, Epoch 2, Loss: 0.9157590866088867, Accuracy: 68.8311996459961, Val Loss: 0.962417721748352, Val Accuracy: 68.19999694824219\n",
            "Iteration 1400, Epoch 2, Loss: 1.1867985725402832, Accuracy: 58.24803161621094, Val Loss: 1.1866799592971802, Val Accuracy: 60.10000228881836\n",
            "Iteration 2100, Epoch 3, Loss: 0.7307707667350769, Accuracy: 75.28559112548828, Val Loss: 1.0219868421554565, Val Accuracy: 67.19999694824219\n",
            "Iteration 2100, Epoch 3, Loss: 1.069308876991272, Accuracy: 62.58512878417969, Val Loss: 1.2120565176010132, Val Accuracy: 58.70000076293945\n",
            "Iteration 2800, Epoch 4, Loss: 0.5894050002098083, Accuracy: 80.24043273925781, Val Loss: 1.1128461360931396, Val Accuracy: 66.69999694824219\n",
            "Iteration 2800, Epoch 4, Loss: 0.9872351288795471, Accuracy: 65.52249145507812, Val Loss: 1.131392002105713, Val Accuracy: 61.5\n",
            "Iteration 3500, Epoch 5, Loss: 0.47803372144699097, Accuracy: 84.08895874023438, Val Loss: 1.206674337387085, Val Accuracy: 65.5999984741211\n",
            "Iteration 3500, Epoch 5, Loss: 0.9175400137901306, Accuracy: 68.08137512207031, Val Loss: 1.2234858274459839, Val Accuracy: 59.60000228881836\n",
            "Iteration 4200, Epoch 6, Loss: 0.40286993980407715, Accuracy: 86.16071319580078, Val Loss: 1.404447317123413, Val Accuracy: 63.900001525878906\n",
            "Iteration 4200, Epoch 6, Loss: 0.8658106923103333, Accuracy: 69.7565689086914, Val Loss: 1.1282824277877808, Val Accuracy: 62.5\n",
            "Iteration 4900, Epoch 7, Loss: 0.3554515540599823, Accuracy: 87.5307388305664, Val Loss: 1.4243385791778564, Val Accuracy: 63.400001525878906\n",
            "Iteration 4900, Epoch 7, Loss: 0.8126839399337769, Accuracy: 71.5932388305664, Val Loss: 1.2016550302505493, Val Accuracy: 60.29999923706055\n",
            "Iteration 5600, Epoch 8, Loss: 0.29862791299819946, Accuracy: 89.44168853759766, Val Loss: 1.5622305870056152, Val Accuracy: 63.70000076293945\n",
            "Iteration 5600, Epoch 8, Loss: 0.7653319835662842, Accuracy: 73.28059387207031, Val Loss: 1.2797200679779053, Val Accuracy: 60.5\n",
            "Iteration 6300, Epoch 9, Loss: 0.24583488702774048, Accuracy: 91.3927001953125, Val Loss: 1.8232041597366333, Val Accuracy: 63.80000305175781\n",
            "Iteration 6300, Epoch 9, Loss: 0.716649055480957, Accuracy: 74.93677520751953, Val Loss: 1.4127455949783325, Val Accuracy: 57.400001525878906\n",
            "Iteration 7000, Epoch 10, Loss: 0.220302015542984, Accuracy: 92.09988403320312, Val Loss: 1.855139136314392, Val Accuracy: 63.599998474121094\n",
            "Iteration 7000, Epoch 10, Loss: 0.6346768736839294, Accuracy: 77.75992584228516, Val Loss: 1.391116738319397, Val Accuracy: 59.20000076293945\n",
            "Finished executing code segment: accuracy=59.20000076293945, model_size=128554\n",
            "Finished executing code segment: accuracy=63.599997758865356, model_size=183242\n",
            "Average accuracy: 61.399999260902405, Model size: 183242\n",
            "Evaluating child : \n",
            " from utils import *\n",
            "import os\n",
            "import tensorflow as tf\n",
            "import numpy as np\n",
            "import math\n",
            "import timeit\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "USE_GPU = True\n",
            "\n",
            "if USE_GPU:\n",
            "    device = '/device:GPU:0'\n",
            "else:\n",
            "    device = '/cpu:0'\n",
            "\n",
            "class ChildConvNet(tf.keras.Model):\n",
            "    def __init__(self):\n",
            "        super(ChildConvNet, self).__init__()\n",
            "\n",
            "        num_classes = 10\n",
            "        input_shape = (32,32,3)\n",
            "        channels = [64, 128]\n",
            "\n",
            "        initializer = tf.initializers.VarianceScaling(scale=2.0, seed=42)\n",
            "\n",
            "        # Stride = 1, Padding = same to keep dimensions small and same\n",
            "        self.conv1 = tf.keras.layers.Conv2D(channels[0], (3,3), strides=1, padding='same', input_shape=input_shape, kernel_initializer=initializer)\n",
            "        self.batch1 = tf.keras.layers.BatchNormalization()\n",
            "        self.act1 = tf.keras.layers.Activation('relu')\n",
            "\n",
            "        self.conv2 = tf.keras.layers.Conv2D(channels[1], (3,3), strides=1, padding='same', kernel_initializer=initializer)\n",
            "        self.batch2 = tf.keras.layers.BatchNormalization()\n",
            "        self.act2 = tf.keras.layers.Activation('relu')\n",
            "\n",
            "        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n",
            "\n",
            "        self.dense = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
            "\n",
            "    def call(self, input_tensor, training=False):\n",
            "        x = self.conv1(input_tensor)\n",
            "        x = self.batch1(x, training=training)\n",
            "        x = self.act1(x)\n",
            "        x = self.conv2(x)\n",
            "        x = self.batch2(x, training=training)\n",
            "        x = self.act2(x)\n",
            "        x = self.gap(x)\n",
            "        x = self.dense(x)\n",
            "        return x\n",
            "\n",
            "def main():\n",
            "  print_every = 700\n",
            "  num_epochs = 10\n",
            "\n",
            "  model = ChildConvNet()\n",
            "\n",
            "  def model_init_fn():\n",
            "      return ChildConvNet()\n",
            "\n",
            "  def optimizer_init_fn():\n",
            "      learning_rate = 1e-3\n",
            "      return tf.keras.optimizers.Adam(learning_rate)\n",
            "\n",
            "  acc, params = train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)\n",
            "\n",
            "  return acc, params\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    accuracy, model_size = main()\n",
            "    print(f\"Final Accuracy: {accuracy*100}%, Model Size: {model_size}\")\n",
            "Submitting tasks to the thread pool\n",
            "Executing code segment\n",
            "Executing code segment\n",
            "Iteration 0, Epoch 1, Loss: 2.3015966415405273, Accuracy: 9.375, Val Loss: 2.616966962814331, Val Accuracy: 7.800000190734863\n",
            "Iteration 0, Epoch 1, Loss: 2.3015966415405273, Accuracy: 9.375, Val Loss: 2.616966962814331, Val Accuracy: 7.800000190734863\n",
            "Iteration 700, Epoch 1, Loss: 1.6869460344314575, Accuracy: 39.584075927734375, Val Loss: 1.5357141494750977, Val Accuracy: 45.69999694824219\n",
            "Iteration 700, Epoch 1, Loss: 1.686960220336914, Accuracy: 39.58853530883789, Val Loss: 1.5354326963424683, Val Accuracy: 45.89999771118164\n",
            "Iteration 1400, Epoch 2, Loss: 1.4670735597610474, Accuracy: 48.22834777832031, Val Loss: 1.489870548248291, Val Accuracy: 47.20000076293945\n",
            "Iteration 1400, Epoch 2, Loss: 1.4670863151550293, Accuracy: 48.24803161621094, Val Loss: 1.4909356832504272, Val Accuracy: 47.29999923706055\n",
            "Iteration 2100, Epoch 3, Loss: 1.3824186325073242, Accuracy: 51.41695785522461, Val Loss: 1.4429651498794556, Val Accuracy: 47.70000076293945\n",
            "Iteration 2100, Epoch 3, Loss: 1.3824554681777954, Accuracy: 51.414215087890625, Val Loss: 1.4418991804122925, Val Accuracy: 47.70000076293945\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class EvoPrompting:\n",
        "    def __init__(self, lm, task, seed_folder, T, m, k, n, p, alpha,\n",
        "                 n_evaluations, target_model_size, target_accuracy, seed_evaluation=False, evaluation_path=None):\n",
        "        self.seed_folder = seed_folder # Folder where the seed codes are located\n",
        "        self.seed_evaluation = seed_evaluation # Do we have to evaluate the seed codes?\n",
        "        self.pre_evaluated_seed_metrics = self.load_pre_evaluated_seed_metrics(evaluation_path) # Pre evaluated seed metrics\n",
        "        self.lm = lm # the crossover LM\n",
        "        self.temperatures = [0.2, 0.6, 0.8, 1.0] # uniformly sample from these temperaturs\n",
        "        # self.environment = environment # In our case CartPole-v1\n",
        "        self.T = T # Number of rounds\n",
        "        self.m = m # number of few-shot prompts per round\n",
        "        self.n = n # number of samples to generate per prompt,\n",
        "        self.k = k # number of in-context examples per prompt\n",
        "        self.p = p # number of survivors to select per generation\n",
        "        self.n_evaluations = n_evaluations # Number of times to run each model\n",
        "        self.alpha = alpha # the upper threshold for the test error\n",
        "        self.global_population = [] # Global historical Population\n",
        "\n",
        "        self.target_model_size = target_model_size # Target model size of the few shot prompt\n",
        "        self.target_accuracy = target_accuracy # Target number of episodes of the few shot prompt\n",
        "\n",
        "        # Set initial well designed architectures as parent models.\n",
        "        # (Evaluate them useing the same eval function as used in the aalgo)\n",
        "        self.current_population = []\n",
        "        self.initialize_population()\n",
        "\n",
        "\n",
        "    def read_seed_files(self, file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            return file.read()\n",
        "\n",
        "\n",
        "    def load_pre_evaluated_seed_metrics(self, file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            return json.load(file)\n",
        "\n",
        "\n",
        "    def initialize_population(self):\n",
        "        # Initialize the population with seed architectures\n",
        "        # List all the Python files in the seed folder\n",
        "        seed_files = [f for f in os.listdir(self.seed_folder) if f.endswith('.py')]\n",
        "\n",
        "        for seed_file in seed_files:\n",
        "            # print(\"EVALUATING SEED: \", seed_file)\n",
        "            seed_file_path = os.path.join(self.seed_folder, seed_file)\n",
        "            seed_code = self.read_seed_files(seed_file_path)\n",
        "            # print(seed_code.type())\n",
        "            # seed_code = np.array([seed_code1[0],seed_code1[1]])\n",
        "\n",
        "            if self.seed_evaluation:\n",
        "                accuracy, model_size = self.eval_t(seed_code)\n",
        "            else:\n",
        "                json= self.pre_evaluated_seed_metrics[seed_file]\n",
        "                # convert string to float\n",
        "                accuracy = float(json[\"accuracy\"])\n",
        "                model_size = float(json[\"model_size\"])\n",
        "\n",
        "\n",
        "            if(accuracy==0):\n",
        "              print(\"ERROR IN SEED\")\n",
        "              continue\n",
        "            else :\n",
        "              # print(\"EVALUATED SEED: \", seed_file, \"accuracy: \", accuracy, \"model_size: \", model_size)\n",
        "              metrics = {\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"model_size\": model_size,\n",
        "              }\n",
        "\n",
        "              fitness_score = accuracy * model_size\n",
        "              self.global_population.append((seed_code, metrics, fitness_score))\n",
        "              self.current_population.append((seed_code, metrics, fitness_score))\n",
        "\n",
        "\n",
        "    def make_few_shot_prompt(self, in_context_examples):\n",
        "        # Create a few-shot prompt using the in context examples E\n",
        "        min_accuracy = float('inf')\n",
        "        min_model_size = float('inf')\n",
        "        prompt = \"Given below are a few seeds for architecture to run on Cifar10 dataset. \\\n",
        "        Your job is to generate a new different and improved child architecture based on the seed architectures given.\\\n",
        "        Also keep in mind the dimensions of Cifar10 data while designing layers for the neural net. \\\n",
        "        Use the same function 'train_part34' from 'utils' to train the model the same way as shown in the seed.\\\n",
        "        Return accuracy & no.of parameters. You can experiment with hyperparameters as well. Your response\\\n",
        "        should be only text that can be executed by python interpreter and nothing else. Don't include any text like\\\n",
        "        ``` python etc\" # Initialize empty prompt string\n",
        "\n",
        "        for example in in_context_examples:\n",
        "            metrics = example[1]\n",
        "            min_accuracy = min(min_accuracy, metrics['accuracy']) # Retrieve the minium avg episodes of the parent architectures\n",
        "            min_model_size = min(min_model_size, metrics['model_size']) # Retrieve the minium model size of the parent architectures\n",
        "            prompt += f'\\nMetrics : {example[1]}\\n\\n'\n",
        "            prompt += f'\\nCode : {example[0]}\\n\\n'\n",
        "\n",
        "        target_accuracy = min_accuracy * self.target_accuracy\n",
        "        target_model_size = min_model_size * self.target_model_size\n",
        "\n",
        "        prompt+= f'\\nTarget Accuracy : {target_accuracy}\\n\\n'\n",
        "        prompt+= f'\\ntarget_model_size : {target_model_size}\\n\\n'\n",
        "        prompt += f'Code:\\n'\n",
        "        # print(prompt)\n",
        "        return prompt\n",
        "\n",
        "\n",
        "    def generate_child (self, prompt):\n",
        "        child_code = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{'role':'user','content': f'{prompt}'}],\n",
        "            temperature=np.random.choice(self.temperatures, size=1, replace=True).item()\n",
        "            # n=1\n",
        "            # max_tokens = 1000\n",
        "\n",
        "        )\n",
        "        # print(\"child code=\\n\\n \", child_code.choices[0].message['content'])\n",
        "        return child_code.choices[0].message['content']\n",
        "\n",
        "\n",
        "    def eval_t(self, code_segment):\n",
        "\n",
        "        # To execute 'main' from seed\n",
        "        def single_evaluation():\n",
        "            print(\"Executing code segment\")\n",
        "            # print(code_segment)\n",
        "            # print(globals()['main'](self.environment))\n",
        "\n",
        "            try:\n",
        "              exec(code_segment, globals())  # Add globals() here\n",
        "              accuracy, model_size = main()\n",
        "              print(f\"Finished executing code segment: accuracy={accuracy*100}, model_size={model_size}\")\n",
        "              return accuracy*100, model_size\n",
        "\n",
        "            except Exception as e:\n",
        "              print(f\"An error occurred: Moving to the next iteration\", e)\n",
        "              return None,0\n",
        "\n",
        "\n",
        "        sum_accuracy = 0\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            print(\"Submitting tasks to the thread pool\")\n",
        "            # count = 1\n",
        "            futures = [executor.submit(single_evaluation) for _ in range(self.n_evaluations)]\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                accuracy, model_size = future.result()\n",
        "                if (accuracy):\n",
        "                  sum_accuracy += accuracy\n",
        "                  # count+=1\n",
        "\n",
        "        avg_accuracy = sum_accuracy / self.n_evaluations\n",
        "        print(f\"Average accuracy: {avg_accuracy}, Model size: {model_size}\")\n",
        "        return avg_accuracy, model_size\n",
        "\n",
        "\n",
        "    def get_top(self, global_population):\n",
        "        \"\"\"\n",
        "        Returns the top entries from the global_population based on their fitness scores.\n",
        "\n",
        "        This function takes a list of global_population entries, where each entry is a tuple containing:\n",
        "        (code, metadata, fitness_score). It sorts the entries based on their fitness scores in descending\n",
        "        order and returns the top num_top entries.\n",
        "\n",
        "        Parameters:\n",
        "        global_population (list): A list of tuples, where each tuple represents an entry in the global\n",
        "                                population, containing (code, metadata, fitness_score).\n",
        "        num_top (int, optional): The number of top entries to return. Defaults to 5.\n",
        "\n",
        "        Returns:\n",
        "        list: A list containing the top num_top entries from the global_population based on their fitness\n",
        "            scores.\n",
        "        \"\"\"\n",
        "        sorted_population = sorted(global_population, key=lambda x: x[2], reverse=True)\n",
        "        top_entries = sorted_population[:self.p]\n",
        "        return top_entries\n",
        "\n",
        "\n",
        "    def cross_mutation(self):\n",
        "        child_architectures = [] # C is the set of architectures of length k\n",
        "        for _ in range(self.m): # create m number of few shot prompts\n",
        "            in_context_examples = random.sample(self.current_population, self.k) # Pick k amount of parents from P\n",
        "\n",
        "            # in_context_examples = random.sample(self.global_population, self.k)\n",
        "\n",
        "            prompt = self.make_few_shot_prompt(in_context_examples)\n",
        "            Ci = [self.generate_child(prompt) for _ in range(self.n)]\n",
        "            child_architectures.extend(Ci)\n",
        "        return child_architectures\n",
        "\n",
        "\n",
        "    def fitness_function(self, model_size, accuracy):\n",
        "        if(model_size):\n",
        "          return model_size * accuracy\n",
        "        else :\n",
        "          return 0\n",
        "\n",
        "\n",
        "    def filter_and_eval(self, child_architectures, alpha):\n",
        "        CEVALED = []\n",
        "        for code_segment in child_architectures:\n",
        "            print(\"Evaluating child : \\n\", code_segment)\n",
        "            avg_accuracy, model_size = self.eval_t(code_segment)\n",
        "            if avg_accuracy!=0 :\n",
        "              if avg_accuracy < alpha : # filter out the bad models\n",
        "                  metrics = {\n",
        "                      \"accuracy\": avg_accuracy,\n",
        "                      \"model_size\": model_size,\n",
        "                  }\n",
        "                  fitness_score = self.fitness_function(model_size, avg_accuracy)\n",
        "                  CEVALED.append((code_segment, metrics, fitness_score))\n",
        "            else :\n",
        "              print(\"Error in child code generated by the GPT\")\n",
        "        return CEVALED\n",
        "\n",
        "\n",
        "    def train(self, CEVALED):\n",
        "        # The original author of the paper proposes a soft prompt tune method here\n",
        "        # I need a model here that can be soft promt tuned, probably gpt2 on huggingface.\n",
        "        pass\n",
        "\n",
        "    def evolve(self):\n",
        "        t = 0\n",
        "        while t < self.T: # number of evoluationary rounds\n",
        "            child_architectures = self.cross_mutation() # Generate the set of code samples\n",
        "            # print(\"Evaluating the following child architectures : \")\n",
        "            # print(child_architectures)\n",
        "            evaluated_children = self.filter_and_eval(child_architectures, self.alpha)\n",
        "            if len(evaluated_children) > 0:\n",
        "              self.global_population.extend(evaluated_children)\n",
        "\n",
        "            if t < self.T - 1:\n",
        "                self.current_population = self.get_top(global_population=self.global_population)\n",
        "                #run without training\n",
        "                #self.lm = self.train(self.lm, [c for c, _ in evaluated_children if c not in self.current_population])\n",
        "\n",
        "            t += 1\n",
        "\n",
        "        return self.get_top(global_population=self.global_population)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the EvoPrompting class\n",
        "    T = 10 # Number of rounds\n",
        "    m = 1 # number of few-shot prompts per round\n",
        "    n = 1 # number of samples to generate per prompt,\n",
        "    k = 3 # number of in-context examples per prompt\n",
        "    p = 3 # number of survivors to select per generation\n",
        "    n_evaluations = 2 # Number of times to run each model\n",
        "    alpha = 96 # TBD (cutoff accuracy for evaluated children)\n",
        "    task = \"create a solution that genreates the best model with the smallest paramter size\"\n",
        "    # environment = \"CartPole-v1\" # environment of the task\n",
        "    seed_folder = \"/cifar/seeds\" # Folder which contains al the initial seed architectures\n",
        "    lm = \"gpt-4.0\" # Language model to use for prompt generation\n",
        "\n",
        "    target_model_factor = 0.90\n",
        "    target_episodes = 0.95\n",
        "\n",
        "    evo_prompt = EvoPrompting(lm, task, seed_folder, T, m, k, n, p, alpha,\n",
        "                              n_evaluations, target_model_factor, target_episodes, seed_evaluation=True,\n",
        "                              evaluation_path=\"\")\n",
        "    # Run the main evolutionary loop\n",
        "    evo_prompt.evolve()\n",
        "\n",
        "    # evo_prompt.initialize_population()\n",
        "    # print(\"evorpompt Global Population: \", evo_prompt.global_population)\n",
        "\n",
        "    top = evo_prompt.get_top(global_population = evo_prompt.global_population)\n",
        "\n",
        "    print('top\\n')\n",
        "    for code in top :\n",
        "      for i in code :\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB8yBMgKR6KQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
